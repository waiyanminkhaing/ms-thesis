{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file downloaded from S3 successfully!\n"
     ]
    }
   ],
   "source": [
    "# S3 Setup\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket_name = \"ms-thesis-sagemaker\"  # Replace with your S3 bucket\n",
    "s3_file_path = \"mbert_bpe_hf_dataset.zip\"  # Replace with the file name in S3\n",
    "local_zip_path = \"/home/ec2-user/SageMaker/ms-thesis/model-variants/mbert_bpe_hf_dataset.zip\"  # Where to save in SageMaker\n",
    "\n",
    "# Download the ZIP file from S3\n",
    "s3.download_file(bucket_name, s3_file_path, local_zip_path)\n",
    "print(\"ZIP file downloaded from S3 successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "extract_path = \"/home/ec2-user/SageMaker/ms-thesis/model-variants/\"  # Where to extract\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(local_zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"ZIP file extracted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file deleted to free space.\n"
     ]
    }
   ],
   "source": [
    "os.remove(local_zip_path)\n",
    "print(\"ZIP file deleted to free space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence_transformers sentencepiece evaluate sacrebleu bert-score peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update -n base -c conda-forge conda -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install conda-forge::rouge-score -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 17:27:03.218709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-12 17:27:03.242445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-12 17:27:03.242480: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-12 17:27:03.257184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-12 17:27:04.055766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Transformers is only compatible with Keras 2, but you have explicitly set `TF_USE_LEGACY_KERAS` to `0`. This may result in unexpected behaviour or errors if Keras 3 objects are passed to Transformers models.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from utils.dataframe import (\n",
    "    load_gen_df, save_tmp_df, load_tmp_df,\n",
    "    save_model_variants_df, load_model_variants_df,\n",
    "    save_model_variants_arrow, load_model_variants_arrow\n",
    ")\n",
    "from utils.gpu import get_device\n",
    "from utils.custom_class import MaskedTextDataset, EvaluationDataset, TextDataset\n",
    "from utils.common import (\n",
    "    generate_masked_predictions_batch,\n",
    "    generate_mt5_predictions_batch,\n",
    "    compute_metrics_batch,\n",
    "    compute_multilingual_masked_perplexity_batch,\n",
    "    compute_multilingual_mt5_perplexity_batch,\n",
    "    convert_to_mean_scores_df\n",
    ")\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import prune\n",
    "from transformers import (\n",
    "    logging,\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM,\n",
    "    Trainer, TrainingArguments, LongformerConfig, LongformerModel,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# from optimum.intel.openvino import OVModelForMaskedLM, OVModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific warnings from the transformers library\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 17:27:09.082541: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Using PyTorch device: cuda\n",
      "GPU Name: NVIDIA A10G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 17:27:09.121856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-12 17:27:09.123844: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# gpu device \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spt models\n",
    "spt_models = {\n",
    "    \"bpe\": spm.SentencePieceProcessor(\"spt/spt_bpe.model\"),\n",
    "    #\"unigram\": spm.SentencePieceProcessor(\"spt/spt_unigram.model\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model names\n",
    "train_model_names = {\n",
    "    \"mBERT\": \"bert-base-multilingual-cased\",\n",
    "    #\"mT5\": \"google/mt5-small\",\n",
    "    #\"XLM-R\": \"xlm-roberta-base\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tokenizers\n",
    "train_tokenizers = {\n",
    "    \"mBERT\": AutoTokenizer.from_pretrained(train_model_names[\"mBERT\"]),\n",
    "    #\"mT5\": AutoTokenizer.from_pretrained(train_model_names[\"mT5\"], use_fast=False, legacy=True),\n",
    "    #\"XLM-R\": AutoTokenizer.from_pretrained(train_model_names[\"XLM-R\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(model, model_name):\n",
    "    \"\"\"\n",
    "    Applies LoRA for efficient fine-tuning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select correct LoRA target layers\n",
    "    if \"t5\" in model_name.lower():\n",
    "        target_modules = [\"q\", \"v\"]  # LoRA for T5/mT5\n",
    "    else:\n",
    "        target_modules = [\"query\", \"value\"]  # LoRA for BERT\n",
    "\n",
    "    # Define LoRA Configuration\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,                    # Rank of LoRA matrices\n",
    "        lora_alpha=16,          # Scaling factor\n",
    "        target_modules=target_modules,  \n",
    "        lora_dropout=0.1,       # Prevents overfitting\n",
    "        bias=\"none\"\n",
    "    )\n",
    "\n",
    "    # Apply LoRA\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Move model to GPU\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"LoRA applied to {model_name} (Target Modules: {target_modules})\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing\n",
    "Datasets used for training:\n",
    "- myXNLI & ALT Corpus (normalized)\n",
    "- Back-translated datasets (NLLB, Seamless M4T)\n",
    "- Pseudo-parallel datasets (MiniLM, LaBSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "def load_and_rename_columns_multilingual(file_name):\n",
    "    df = load_gen_df(f\"{file_name}\")\n",
    "\n",
    "    column_mapping = {\n",
    "        \"english\": \"source\",\n",
    "        \"burmese\": \"target\",\n",
    "        \"english_back_translated\": \"source\",\n",
    "        \"burmese_translated\": \"target\",\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ensure only required columns exist\n",
    "    df = df[[\"source\", \"target\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "datasets = {\n",
    "    \"normal\": [\n",
    "        \"myxnli_normalized_1\", \n",
    "        \"myxnli_normalized_2\", \n",
    "        \"alt_combined_normalized\"\n",
    "    ],\n",
    "    \"nllb_back_translated\": [\n",
    "        \"myxnli_nllb_back_translated_final_1\", \n",
    "        \"myxnli_nllb_back_translated_final_2\", \n",
    "        \"alt_combined_nllb_back_translated_final\"\n",
    "    ],\n",
    "    \"seamless_m4t_back_translated\": [\n",
    "        \"myxnli_seamless_m4t_back_translated_final_1\", \n",
    "        \"myxnli_seamless_m4t_back_translated_final_2\", \n",
    "        \"alt_combined_seamless_m4t_back_translated_final\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process datasets\n",
    "loaded_datasets = {}\n",
    "for key, file_list in datasets.items():\n",
    "    loaded_datasets[key] = [load_and_rename_columns_multilingual(file) for file in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all datasets\n",
    "combined = pd.concat(\n",
    "    loaded_datasets[\"normal\"] + \n",
    "    loaded_datasets[\"nllb_back_translated\"] + \n",
    "    loaded_datasets[\"seamless_m4t_back_translated\"],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to prevent order bias\n",
    "combined = combined.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archaeologists think that a fire broke out in ...</td>\n",
       "      <td>ရှေးဟောင်းသုတေသီတွေက Knossos မှာ မီးလောင်တာ BC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are political meetings in every neighbor...</td>\n",
       "      <td>ရပ်ကွက်တိုင်းမှာ နိုင်ငံရေး အစည်းအဝေးတွေရှိတယ်။</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lawyer said that in article 712 (1) gao wa...</td>\n",
       "      <td>ရှေ့နေက ပုဒ်မ ၇၁၂ (၁) မှာ Gao ကို ငွေကြေးဆိုင်...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>things can get confusing when talking about do...</td>\n",
       "      <td>Dordogne အကြောင်းပြောသောအခါ၊ ဝေးကွာသောနေရာများ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>making financial management a top priority acr...</td>\n",
       "      <td>ဘဏ္ဍာရေး စီမံခန့်ခွဲမှုကို ပြည်ထောင်စု အစိုးရတ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  archaeologists think that a fire broke out in ...   \n",
       "1  there are political meetings in every neighbor...   \n",
       "2  the lawyer said that in article 712 (1) gao wa...   \n",
       "3  things can get confusing when talking about do...   \n",
       "4  making financial management a top priority acr...   \n",
       "\n",
       "                                              target  \n",
       "0  ရှေးဟောင်းသုတေသီတွေက Knossos မှာ မီးလောင်တာ BC...  \n",
       "1    ရပ်ကွက်တိုင်းမှာ နိုင်ငံရေး အစည်းအဝေးတွေရှိတယ်။  \n",
       "2  ရှေ့နေက ပုဒ်မ ၇၁၂ (၁) မှာ Gao ကို ငွေကြေးဆိုင်...  \n",
       "3  Dordogne အကြောင်းပြောသောအခါ၊ ဝေးကွာသောနေရာများ...  \n",
       "4  ဘဏ္ဍာရေး စီမံခန့်ခွဲမှုကို ပြည်ထောင်စု အစိုးရတ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display combined dataset\n",
    "display(combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset length: 1627576\n"
     ]
    }
   ],
   "source": [
    "# print length\n",
    "print(f\"Combined dataset length: {len(combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "save_model_variants_df(combined, \"combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples, tokenizer, spt_tokenizer, model_name):\n",
    "    \"\"\"\n",
    "    Tokenizes Burmese text using the selected SentencePiece model before applying Transformer tokenization.\n",
    "    \"\"\"\n",
    "    # Apply SentencePiece Tokenization for Burmese target text\n",
    "    spt_burmese = [\" \".join(spt_tokenizer.encode_as_pieces(text)) for text in examples[\"target\"]]\n",
    "    examples[\"target\"] = spt_burmese  # Overwrite with tokenized text\n",
    "\n",
    "    if \"t5\" in model_name.lower():\n",
    "        # mT5/T5 (Text-to-Text) - Tokenize source & target separately\n",
    "        model_inputs = tokenizer(\n",
    "            examples[\"source\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "        # Tokenize target`\n",
    "        labels = tokenizer(\n",
    "            examples[\"target\"],  \n",
    "            padding=\"max_length\",  \n",
    "            truncation=True,  \n",
    "            max_length=512,\n",
    "            return_special_tokens_mask=True  # Helps handle special tokens\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        model_inputs[\"labels\"] = labels\n",
    "        model_inputs[\"decoder_input_ids\"] = labels\n",
    "        return model_inputs\n",
    "\n",
    "    # BERT-based models (Masked/Causal LM)\n",
    "    inputs = tokenizer(\n",
    "        examples[\"source\"],\n",
    "        examples[\"target\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Assign labels for causal LM (BERT-like models)\n",
    "    inputs[\"labels\"] = deepcopy(inputs[\"input_ids\"])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize for each model and spt\n",
    "for model_name, tokenizer in train_tokenizers.items():\n",
    "    for spt_name, spt_tokenizer in spt_models.items():\n",
    "        dataset = load_model_variants_df(\"combined\")\n",
    "\n",
    "        # Convert to Hugging Face Dataset\n",
    "        dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "        # apply tokenize\n",
    "        dataset = dataset.map(\n",
    "            lambda x, _: tokenize(x, tokenizer, spt_tokenizer, model_name),\n",
    "            batched=True,\n",
    "            desc=f\"Tokenizing dataset for {model_name} with {spt_name}\",\n",
    "            with_indices=True,  # Passing index as a second argument\n",
    "            num_proc=10\n",
    "        )\n",
    "\n",
    "        # save\n",
    "        save_model_variants_arrow(dataset, f\"{model_name.lower()}_{spt_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fine-Tuning Transformer Models for Burmese\n",
    "This notebook fine-tunes three transformer models:\n",
    "- mBERT (best perplexity, but weak BLEU/ROUGE)\n",
    "- mT5 (best for generation, but requires more data)\n",
    "- XLM-R (good BLEU/ROUGE, but poor perplexity)\n",
    "\n",
    "Apply:\n",
    "- Sentence-Piece Tokenization for Burmese segmentation\n",
    "- LoRA for efficient fine-tuning\n",
    "- Prefix-Tuning for lightweight adaptations\n",
    "- Mixed Precision Training for speed improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "train_models = {\n",
    "    \"mBERT\": AutoModelForMaskedLM.from_pretrained(train_model_names[\"mBERT\"], num_labels=1).to(device),\n",
    "    #\"mT5\": AutoModelForSeq2SeqLM.from_pretrained(train_model_names[\"mT5\"]).to(device),\n",
    "    #\"XLM-R\": AutoModelForMaskedLM.from_pretrained(train_model_names[\"XLM-R\"], num_labels=1).to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5abf0161d34ad28e2bcc0d1600f6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenized dataset\n",
    "tokenized_datasets = {\n",
    "    model_name: {\n",
    "        spt_name: load_model_variants_arrow(f\"{model_name.lower()}_{spt_name}\")\n",
    "        for spt_name in spt_models.keys()\n",
    "    }\n",
    "    for model_name in train_tokenizers.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model_name, spt_name):\n",
    "    \"\"\"\n",
    "    Fine-tunes the model with LoRA on the specified SentencePiece tokenization (SPT).\n",
    "    \"\"\"\n",
    "    print(f\"Fine-tuning {model_name} using SPT-{spt_name.upper()}...\")\n",
    "\n",
    "    # Load tokenizer & model\n",
    "    tokenizer = train_tokenizers[model_name]\n",
    "    model = train_models[model_name]\n",
    "\n",
    "    # Move model to GPU before applying LoRA\n",
    "    model.to(device)\n",
    "\n",
    "    # Apply LoRA for efficient parameter tuning\n",
    "    model = apply_lora(model, model_name)\n",
    "\n",
    "    # Tokenize dataset & split into training and validation sets\n",
    "    tokenized_dataset = tokenized_datasets[model_name][spt_name]\n",
    "    split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    \n",
    "    train_data = split_dataset[\"train\"]\n",
    "    val_data = split_dataset[\"test\"]\n",
    "\n",
    "    # for debug, remove comment\n",
    "    #train_data = train_data.select(range(100))\n",
    "    #val_data = val_data.select(range(100))\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"model-variants/results/{model_name}_{spt_name.upper()}\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=3e-5,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        fp16=False,\n",
    "        bf16=True,\n",
    "        eval_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"loss\",\n",
    "        greater_is_better=False,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=1000,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        auto_find_batch_size=True,\n",
    "        disable_tqdm=False,\n",
    "        label_names=[\"labels\"],\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save trained model and tokenizer\n",
    "    save_path = f\"model-variants/models/{model_name}_{spt_name.upper()}\"\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    print(f\"Model `{model_name}` fine-tuned and saved at `{save_path}`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning mBERT using SPT-BPE...\n",
      "LoRA applied to mBERT (Target Modules: ['query', 'value'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85892' max='406895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 85892/406895 8:08:21 < 30:25:11, 2.93 it/s, Epoch 1.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fine tune with SPT-BPE\n",
    "fine_tune_model(\"mBERT\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune with SPT-Unigram\n",
    "fine_tune_model(\"mBERT\", \"unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### mT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning mT5 using SPT-BPE...\n",
      "LoRA applied to mT5 (Target Modules: ['q', 'v'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='813790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    53/813790 00:15 < 68:48:19, 3.29 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fine tune with SPT-BPE\n",
    "fine_tune_model(\"mT5\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune with SPT-Unigram\n",
    "fine_tune_model(\"mT5\", \"unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune with SPT-BPE\n",
    "fine_tune_model(\"XLM-R\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune with SPT-Unigram\n",
    "fine_tune_model(\"XLM-R\", \"unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "mbert_bpe_trained_path = \"model-variants/models/mBERT_SPT-BPE\"\n",
    "mbert_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(mbert_bpe_trained_path)\n",
    "mbert_bpe_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_bpe_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mbert_bpe_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "mbert_bpe_trained_predictions_texts = mbert_bpe_trained_predictions[\"target\"].tolist()\n",
    "mbert_bpe_trained_predictions_dataset = MaskedTextDataset(mbert_bpe_trained_predictions_texts, mbert_bpe_trained_tokenizer)\n",
    "mbert_bpe_trained_predictions_dataloader = DataLoader(\n",
    "    mbert_bpe_trained_predictions_dataset, \n",
    "    batch_size=mbert_bpe_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "mbert_bpe_trained_predictions[\"generated\"] = generate_masked_predictions_batch(\n",
    "    mbert_bpe_trained_predictions_dataloader, \n",
    "    mbert_bpe_trained_model, \n",
    "    mbert_bpe_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(mbert_bpe_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained mbert predictions\n",
    "save_model_variants_df(mbert_bpe_trained_predictions, \"mBERT_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "mbert_unigram_trained_path = \"model-variants/models/mBERT_SPT-UNIGRAM\"\n",
    "mbert_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(mbert_unigram_trained_path)\n",
    "mbert_unigram_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_unigram_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mbert_unigram_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "mbert_unigram_trained_predictions_texts = mbert_unigram_trained_predictions[\"target\"].tolist()\n",
    "mbert_unigram_trained_predictions_dataset = MaskedTextDataset(mbert_unigram_trained_predictions_texts, mbert_unigram_trained_tokenizer)\n",
    "mbert_unigram_trained_predictions_dataloader = DataLoader(\n",
    "    mbert_unigram_trained_predictions_dataset, \n",
    "    batch_size=mbert_unigram_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "mbert_unigram_trained_predictions[\"generated\"] = generate_masked_predictions_batch(\n",
    "    mbert_unigram_trained_predictions_dataloader, \n",
    "    mbert_unigram_trained_model, \n",
    "    mbert_unigram_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(mbert_unigram_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained mbert predictions\n",
    "save_model_variants_df(mbert_unigram_trained_predictions, \"mBERT_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "xlmr_bpe_trained_path = \"model-variants/models/XLM-R_SPT-BPE\"\n",
    "xlmr_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(xlmr_bpe_trained_path)\n",
    "xlmr_bpe_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_bpe_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "xlmr_bpe_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "xlmr_bpe_trained_predictions_texts = xlmr_bpe_trained_predictions[\"target\"].tolist()\n",
    "xlmr_bpe_trained_predictions_dataset = MaskedTextDataset(xlmr_bpe_trained_predictions_texts, xlmr_bpe_trained_tokenizer)\n",
    "xlmr_bpe_trained_predictions_dataloader = DataLoader(\n",
    "    xlmr_bpe_trained_predictions_dataset, \n",
    "    batch_size=xlmr_bpe_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "xlmr_bpe_trained_predictions[\"generated\"] = generate_masked_predictions_batch(\n",
    "    xlmr_bpe_trained_predictions_dataloader, \n",
    "    xlmr_bpe_trained_model, \n",
    "    xlmr_bpe_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(xlmr_bpe_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained xlmr predictions\n",
    "save_model_variants_df(xlmr_bpe_trained_predictions, \"XLM-R_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "xlmr_unigram_trained_path = \"model-variants/models/XLM-R_SPT-UNIGRAM\"\n",
    "xlmr_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(xlmr_unigram_trained_path)\n",
    "xlmr_unigram_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_unigram_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "xlmr_unigram_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "xlmr_unigram_trained_predictions_texts = xlmr_unigram_trained_predictions[\"target\"].tolist()\n",
    "xlmr_unigram_trained_predictions_dataset = MaskedTextDataset(xlmr_unigram_trained_predictions_texts, xlmr_unigram_trained_tokenizer)\n",
    "xlmr_unigram_trained_predictions_dataloader = DataLoader(\n",
    "    xlmr_unigram_trained_predictions_dataset, \n",
    "    batch_size=xlmr_unigram_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "xlmr_unigram_trained_predictions[\"generated\"] = generate_masked_predictions_batch(\n",
    "    xlmr_unigram_trained_predictions_dataloader, \n",
    "    xlmr_unigram_trained_model, \n",
    "    xlmr_unigram_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(xlmr_unigram_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained xlmr predictions\n",
    "save_model_variants_df(xlmr_unigram_trained_predictions, \"XLM-R_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mT5 with BPE\n",
    "mt5_bpe_trained_path = \"model-variants/models/mT5_SPT-BPE\"\n",
    "mt5_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(mt5_bpe_trained_path)\n",
    "mt5_bpe_trained_model = AutoModelForSeq2SeqLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_bpe_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mt5_bpe_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "mt5_bpe_trained_predictions_texts = mt5_bpe_trained_predictions[\"target\"].tolist()\n",
    "mt5_bpe_trained_predictions_dataset = TextDataset(mt5_bpe_trained_predictions_texts)\n",
    "mt5_bpe_trained_predictions_dataloader = DataLoader(\n",
    "    mt5_bpe_trained_predictions_dataset, \n",
    "    batch_size=mt5_bpe_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "mt5_bpe_trained_predictions[\"generated\"] = generate_mt5_predictions_batch(\n",
    "    mt5_bpe_trained_predictions_dataloader, \n",
    "    mt5_bpe_trained_model, \n",
    "    mt5_bpe_trained_tokenizer,\n",
    "    spt_models[\"bpe\"],\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(mt5_bpe_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained mt5 predictions\n",
    "save_model_variants_df(mt5_bpe_trained_predictions, \"mT5_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mT5 with Unigram\n",
    "mt5_unigram_trained_path = \"model-variants/models/mT5_SPT-BPE\"\n",
    "mt5_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(mt5_unigram_trained_path)\n",
    "mt5_unigram_trained_model = AutoModelForSeq2SeqLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_unigram_trained_predictions = load_model_variants_df(\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mt5_unigram_trained_predictions_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader\n",
    "mt5_unigram_trained_predictions_texts = mt5_unigram_trained_predictions[\"target\"].tolist()\n",
    "mt5_unigram_trained_predictions_dataset = TextDataset(mt5_unigram_trained_predictions_texts)\n",
    "mt5_unigram_trained_predictions_dataloader = DataLoader(\n",
    "    mt5_unigram_trained_predictions_dataset, \n",
    "    batch_size=mt5_unigram_trained_predictions_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text generation\n",
    "mt5_unigram_trained_predictions[\"generated\"] = generate_mt5_predictions_batch(\n",
    "    mt5_unigram_trained_predictions_dataloader, \n",
    "    mt5_unigram_trained_model, \n",
    "    mt5_unigram_trained_tokenizer,\n",
    "    spt_models[\"unigram\"],\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(mt5_unigram_trained_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained mt5 predictions\n",
    "save_model_variants_df(mt5_unigram_trained_predictions, \"mT5_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Compute BLEU, ROUGE-1, ROUGE-2, ROUGE-3, ROUGE-L, chrF-S, BERTScore and Perplexity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_bpe_trained_metrics = load_model_variants_df(f\"mBERT_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for mBERT with BPE...\"),\n",
    "compute_metrics_batch(mbert_bpe_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for mBERT with BPE:\")\n",
    "print(f\"BLEU Score: {mbert_bpe_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {mbert_bpe_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {mbert_bpe_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {mbert_bpe_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {mbert_bpe_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {mbert_bpe_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(mbert_bpe_trained_metrics, f\"mBERT_bpe_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_unigram_trained_metrics = load_model_variants_df(f\"mBERT_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for mBERT with Unigram...\"),\n",
    "compute_metrics_batch(mbert_unigram_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for mBERT with BPE:\")\n",
    "print(f\"BLEU Score: {mbert_unigram_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {mbert_unigram_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {mbert_unigram_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {mbert_unigram_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {mbert_unigram_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {mbert_unigram_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(mbert_unigram_trained_metrics, f\"mBERT_unigram_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XLM-R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_bpe_trained_metrics = load_model_variants_df(f\"XLM-R_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for XLM-R with BPE...\"),\n",
    "compute_metrics_batch(xlmr_bpe_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for XLM-R with BPE:\")\n",
    "print(f\"BLEU Score: {xlmr_bpe_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {xlmr_bpe_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {xlmr_bpe_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {xlmr_bpe_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {xlmr_bpe_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {xlmr_bpe_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(xlmr_bpe_trained_metrics, f\"XLM-R_bpe_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_unigram_trained_metrics = load_model_variants_df(f\"XLM-R_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for XLM-R with Unigram...\"),\n",
    "compute_metrics_batch(xlmr_unigram_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for mBERT with BPE:\")\n",
    "print(f\"BLEU Score: {xlmr_unigram_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {xlmr_unigram_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {xlmr_unigram_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {xlmr_unigram_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {xlmr_unigram_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {xlmr_unigram_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(xlmr_unigram_trained_metrics, f\"XLM-R_unigram_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_bpe_trained_metrics = load_model_variants_df(f\"mT5_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for mT5 with BPE...\"),\n",
    "compute_metrics_batch(mt5_bpe_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for mT5 with BPE:\")\n",
    "print(f\"BLEU Score: {mt5_bpe_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {mt5_bpe_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {mt5_bpe_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {mt5_bpe_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {mt5_bpe_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {mt5_bpe_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(mt5_bpe_trained_metrics, f\"mT5_bpe_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_unigram_trained_metrics = load_model_variants_df(f\"mT5_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "print(f\"Processing Data for mT5 with Unigram...\"),\n",
    "compute_metrics_batch(mt5_unigram_trained_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "print(f\"Metrics scores for mBERT with BPE:\")\n",
    "print(f\"BLEU Score: {mt5_unigram_trained_metrics['bleu'].mean()}\")\n",
    "print(f\"ROUGE-1 Score: {mt5_unigram_trained_metrics['rouge-1'].mean()}\")\n",
    "print(f\"ROUGE-2 Score: {mt5_unigram_trained_metrics['rouge-2'].mean()}\")\n",
    "print(f\"ROUGE-L Score: {mt5_unigram_trained_metrics['rouge-l'].mean()}\")\n",
    "print(f\"chrF-S Score: {mt5_unigram_trained_metrics['chrf-s'].mean()}\")\n",
    "print(f\"BERT Score: {mt5_unigram_trained_metrics['bert_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "save_tmp_df(mt5_unigram_trained_metrics, f\"mT5_unigram_trained_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_bpe_trained_perplexity = load_model_variants_df(f\"mBERT_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mbert_bpe_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "mbert_bpe_trained_path = \"model-variants/models/mBERT_SPT-BPE\"\n",
    "mbert_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(mbert_bpe_trained_path)\n",
    "mbert_bpe_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "mbert_bpe_trained_generated_texts = mbert_bpe_trained_perplexity[\"generated\"].tolist()\n",
    "mbert_bpe_trained_text_dataset = TextDataset(mbert_bpe_trained_generated_texts)\n",
    "mbert_bpe_trained_dataloader = DataLoader(\n",
    "    mbert_bpe_trained_text_dataset, \n",
    "    batch_size=mbert_bpe_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "mbert_bpe_trained_perplexity[\"perplexity\"] = compute_multilingual_masked_perplexity_batch(\n",
    "    mbert_bpe_trained_dataloader,\n",
    "    mbert_bpe_trained_model,\n",
    "    mbert_bpe_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {mbert_bpe_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(mbert_bpe_trained_perplexity, f\"mBERT_bpe_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mbert_unigram_trained_perplexity = load_model_variants_df(f\"mBERT_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mbert_unigram_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with Unigram\n",
    "mbert_unigram_trained_path = \"model-variants/models/mBERT_SPT-UNIGRAM\"\n",
    "mbert_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(mbert_unigram_trained_path)\n",
    "mbert_unigram_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "mbert_unigram_trained_generated_texts = mbert_unigram_trained_perplexity[\"generated\"].tolist()\n",
    "mbert_unigram_trained_text_dataset = TextDataset(mbert_unigram_trained_generated_texts)\n",
    "mbert_unigram_trained_dataloader = DataLoader(\n",
    "    mbert_unigram_trained_text_dataset, \n",
    "    batch_size=mbert_unigram_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "mbert_unigram_trained_perplexity[\"perplexity\"] = compute_multilingual_masked_perplexity_batch(\n",
    "    mbert_unigram_trained_dataloader,\n",
    "    mbert_unigram_trained_model,\n",
    "    mbert_unigram_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {mbert_bpe_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(mbert_bpe_trained_perplexity, f\"mBERT_bpe_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XLM-R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_bpe_trained_perplexity = load_model_variants_df(f\"XLM-R_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "xlmr_bpe_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for XLMR-R with BPE\n",
    "xlmr_bpe_trained_path = \"model-variants/models/XLM-R_SPT-BPE\"\n",
    "xlmr_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(xlmr_bpe_trained_path)\n",
    "xlmr_bpe_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "xlmr_bpe_trained_generated_texts = xlmr_bpe_trained_perplexity[\"generated\"].tolist()\n",
    "xlmr_bpe_trained_text_dataset = TextDataset(xlmr_bpe_trained_generated_texts)\n",
    "xlmr_bpe_trained_dataloader = DataLoader(\n",
    "    xlmr_bpe_trained_text_dataset, \n",
    "    batch_size=xlmr_bpe_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "xlmr_bpe_trained_perplexity[\"perplexity\"] = compute_multilingual_masked_perplexity_batch(\n",
    "    xlmr_bpe_trained_dataloader,\n",
    "    xlmr_bpe_trained_model,\n",
    "    xlmr_bpe_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {xlmr_bpe_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(xlmr_bpe_trained_perplexity, f\"XLM-R_bpe_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "xlmr_unigram_trained_perplexity = load_model_variants_df(f\"XLM-R_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "xlmr_unigram_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "xlmr_unigram_trained_path = \"model-variants/models/XLM-R_SPT-UNIGRAM\"\n",
    "xlmr_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(xlmr_unigram_trained_path)\n",
    "xlmr_unigram_trained_model = AutoModelForMaskedLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "xlmr_unigram_trained_generated_texts = xlmr_unigram_trained_perplexity[\"generated\"].tolist()\n",
    "xlmr_unigram_trained_text_dataset = TextDataset(xlmr_unigram_trained_generated_texts)\n",
    "xlmr_unigram_trained_dataloader = DataLoader(\n",
    "    xlmr_unigram_trained_text_dataset, \n",
    "    batch_size=xlmr_unigram_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "xlmr_unigram_trained_perplexity[\"perplexity\"] = compute_multilingual_masked_perplexity_batch(\n",
    "    xlmr_unigram_trained_dataloader,\n",
    "    xlmr_unigram_trained_model,\n",
    "    xlmr_unigram_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {xlmr_unigram_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(xlmr_unigram_trained_perplexity, f\"XLM-R_unigram_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_bpe_trained_perplexity = load_model_variants_df(f\"mT5_bpe_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mt5_bpe_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mt5 with BPE\n",
    "mt5_bpe_trained_path = \"model-variants/models/mT5_SPT-BPE\"\n",
    "mt5_bpe_trained_tokenizer = AutoTokenizer.from_pretrained(mt5_bpe_trained_path)\n",
    "mt5_bpe_trained_model = AutoModelForSeq2SeqLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "mt5_bpe_trained_generated_texts = mt5_bpe_trained_perplexity[\"generated\"].tolist()\n",
    "mt5_bpe_trained_text_dataset = TextDataset(mt5_bpe_trained_generated_texts)\n",
    "mt5_bpe_trained_dataloader = DataLoader(\n",
    "    mt5_bpe_trained_text_dataset, \n",
    "    batch_size=mt5_bpe_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "mt5_bpe_trained_perplexity[\"perplexity\"] = compute_multilingual_mt5_perplexity_batch(\n",
    "    mt5_bpe_trained_dataloader,\n",
    "    mt5_bpe_trained_model,\n",
    "    mt5_bpe_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {mt5_bpe_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(mt5_bpe_trained_perplexity, f\"mT5_bpe_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mt5_unigram_trained_perplexity = load_model_variants_df(f\"mT5_unigram_trained_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "mt5_unigram_trained_perplexity_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for mBERT with BPE\n",
    "mt5_unigram_trained_path = \"model-variants/models/mBERT_SPT-UNIGRAM\"\n",
    "mt5_unigram_trained_tokenizer = AutoTokenizer.from_pretrained(mt5_unigram_trained_path)\n",
    "mt5_unigram_trained_model = AutoModelForSeq2SeqLM.from_pretrained().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and DataLoader\n",
    "mt5_unigram_trained_generated_texts = mt5_unigram_trained_perplexity[\"generated\"].tolist()\n",
    "mt5_unigram_trained_text_dataset = TextDataset(mt5_unigram_trained_generated_texts)\n",
    "mt5_unigram_trained_dataloader = DataLoader(\n",
    "    mt5_unigram_trained_text_dataset, \n",
    "    batch_size=mt5_unigram_trained_perplexity_batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and store perplexity scores in DataFrame\n",
    "mt5_unigram_trained_perplexity[\"perplexity\"] = compute_multilingual_mt5_perplexity_batch(\n",
    "    mt5_unigram_trained_dataloader,\n",
    "    mt5_unigram_trained_model,\n",
    "    mt5_unigram_trained_tokenizer,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display perplexity\n",
    "print(f\"Perplexity Score: {mt5_unigram_trained_perplexity['perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save perplexity\n",
    "save_tmp_df(mt5_unigram_trained_perplexity, f\"mT5_unigram_trained_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine evaluation results\n",
    "for model_name in train_model_names.keys():\n",
    "    for spt_name in spt_models.keys():\n",
    "        print(f\"Processing {model_name}...\")\n",
    "\n",
    "        trained_evaluation_results = load_model_variants_df(f\"{model_name}_{spt_name}_trained_predictions\")\n",
    "\n",
    "        # load metrics and set\n",
    "        metrics = load_tmp_df(f\"{model_name}_{spt_name}_metrics\")\n",
    "        trained_evaluation_results[\"bleu\"] = metrics[\"bleu\"]\n",
    "        trained_evaluation_results[\"rouge-1\"] = metrics[\"rouge-1\"]\n",
    "        trained_evaluation_results[\"rouge-2\"] = metrics[\"rouge-2\"]\n",
    "        trained_evaluation_results[\"rouge-l\"] = metrics[\"rouge-l\"]\n",
    "        trained_evaluation_results[\"chrf-s\"] = metrics[\"chrf-s\"]\n",
    "        trained_evaluation_results[\"bert_score\"] = metrics[\"bert_score\"]\n",
    "\n",
    "        # load perplexity and set\n",
    "        perplexity = load_tmp_df(f\"{model_name}_{spt_name}_perplexity\")\n",
    "        trained_evaluation_results[\"perplexity\"] = perplexity[\"perplexity\"]\n",
    "\n",
    "        save_model_variants_df(trained_evaluation_results, f\"{model_name}_{spt_name}_evaluation_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking and Analysis\n",
    "Compare the performance of LSTM BPE, LSTM Unigram, mBERT, and XLM-R using BLEU, ROUGE, chrF-S, BERT Score and Perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trained_benchmarking_datasets = {}\n",
    "for model_name in train_model_names.keys():\n",
    "    for spt_name in spt_models.keys():\n",
    "        df = load_model_variants_df(trained_evaluation_results, f\"{model_name}_{spt_name}_evaluation_results\")\n",
    "        trained_benchmarking_datasets[f\"{model_name} {spt_name.upper()}\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to mean score df\n",
    "trained_benchmarking_mean_scores = convert_to_mean_scores_df(trained_benchmarking_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display mean scores\n",
    "display(trained_benchmarking_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save benchmarking results\n",
    "save_model_variants_df(trained_benchmarking_mean_scores, \"trained_evaluation_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimize Model Efficiency with Lightweight Transformers\n",
    "- Optimizes mBERT, XLM-R, mT5-Small (BPE & Unigram).\n",
    "- Trains TinyBERT, DistilBERT with Knowledge Distillation.\n",
    "- Evaluates BLEU, ROUGE, chrF++ after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Fine-Tuned Teacher Model Paths\n",
    "teacher_models = {\n",
    "    \"mBERT_BPE\": \"model-variants/models/mBERT_SPT-BPE\",\n",
    "    \"mBERT_Unigram\": \"model-variants/models/mBERT_SPT-UNIGRAM\",\n",
    "    \"mT5_BPE\": \"model-variants/models/mT5_SPT-BPE\",\n",
    "    \"mT5_Unigram\": \"model-variants/models/mT5_SPT-UNIGRAM\",\n",
    "    \"XLM-R_BPE\": \"model-variants/models/XLM-R_SPT_BPE\",\n",
    "    \"XLM-R_Unigram\": \"model-variants/models/XLM-R_SPT-UNIGRAM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Student Models (TinyBERT & DistilBERT)\n",
    "student_models = {\n",
    "    \"TinyBERT\": \"huawei-noah/TinyBERT_General_6L_768D\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Student Models with Knowledge Distillation\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, teacher_model, alpha=0.5, temperature=2.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "        self.teacher_model.eval()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        student_outputs = model(**inputs)\n",
    "        student_logits = student_outputs.logits\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = self.teacher_model(**inputs)\n",
    "            teacher_logits = teacher_outputs.logits.detach()\n",
    "\n",
    "        loss_ce = nn.CrossEntropyLoss()(student_logits.view(-1, student_logits.size(-1)), inputs[\"labels\"].view(-1))\n",
    "        loss_kl = nn.KLDivLoss(reduction=\"batchmean\")(\n",
    "            torch.nn.functional.log_softmax(student_logits / self.temperature, dim=-1),\n",
    "            torch.nn.functional.softmax(teacher_logits / self.temperature, dim=-1),\n",
    "        ) * (self.temperature ** 2)\n",
    "\n",
    "        loss = self.alpha * loss_ce + (1 - self.alpha) * loss_kl\n",
    "        return (loss, student_outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fine tuned model with knowledge distillation\n",
    "def train_distilled_model(student_model_name, teacher_model_name, teacher_path):\n",
    "    print(f\"🚀 Training {student_model_name} using {teacher_model_name} as a teacher...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(teacher_path)\n",
    "\n",
    "    # ✅ Select Correct Model Type\n",
    "    if \"t5\" in teacher_model_name.lower():\n",
    "        teacher_model = AutoModelForSeq2SeqLM.from_pretrained(teacher_path).to(device)\n",
    "        student_model = AutoModelForSeq2SeqLM.from_pretrained(STUDENT_MODELS[student_model_name]).to(device)\n",
    "    else:\n",
    "        teacher_model = AutoModelForMaskedLM.from_pretrained(teacher_path).to(device)\n",
    "        student_model = AutoModelForMaskedLM.from_pretrained(STUDENT_MODELS[student_model_name]).to(device)\n",
    "\n",
    "    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1%]\")\n",
    "    dataset = dataset.map(lambda x: tokenizer(x[\"article\"], padding=\"max_length\", truncation=True), batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./models/{student_model_name}_distilled\",\n",
    "        per_device_train_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=5e-5,\n",
    "        save_strategy=\"epoch\",\n",
    "        fp16=True\n",
    "    )\n",
    "\n",
    "    trainer = DistillationTrainer(teacher_model=teacher_model, model=student_model, args=training_args, tokenizer=tokenizer)\n",
    "    trainer.train()\n",
    "    student_model.save_pretrained(f\"./models/{student_model_name}_distilled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
