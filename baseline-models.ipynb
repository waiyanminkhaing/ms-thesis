{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence_transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sentencepiece as spm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from rouge_score import rouge_scorer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# for mac\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(\"GPU details: \", details)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# set GPU device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window / Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window\n",
    "print(\"Tensorflow GPUs: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using PyTorch device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save models df\n",
    "def save_models_df(df, df_name):\n",
    "    df.to_csv(f\"models/{df_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load spt df\n",
    "def load_spt_df(df_name):\n",
    "    return pd.read_csv(f\"spt/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load models df\n",
    "def load_models_df(df_name):\n",
    "    return pd.read_csv(f\"models/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and file paths\n",
    "datasets = {\n",
    "    \"normal\": [\n",
    "        \"tokenized_bpe_myxnli_normalized_1\", \n",
    "        \"tokenized_bpe_myxnli_normalized_2\", \n",
    "        \"tokenized_bpe_alt_combined_normalized\"\n",
    "    ],\n",
    "    \"nllb_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_1\", \n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_2\", \n",
    "        \"tokenized_bpe_alt_combined_nllb_back_translated_final\"\n",
    "    ],\n",
    "    \"seamless_m4t_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_1\",\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_2\",\n",
    "        \"tokenized_bpe_alt_combined_seamless_m4t_back_translated_final\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "def load_and_rename_columns(file_name):\n",
    "    df = load_spt_df(f\"{file_name}\")\n",
    "\n",
    "    column_mapping = {\n",
    "        \"english_back_translated\": \"english\",\n",
    "        \"burmese_translated\": \"burmese\",\n",
    "        \"english_back_translated_tokens\": \"english_tokens\",\n",
    "        \"burmese_translated_tokens\": \"burmese_tokens\",\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ensure only required columns exist\n",
    "    df = df[[\"english\", \"burmese\", \"english_tokens\", \"burmese_tokens\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "all_datasets = {\n",
    "    key: [load_and_rename_columns(file) for file in file_list] for key, file_list in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "combined_data = pd.concat(\n",
    "    all_datasets[\"normal\"] + \n",
    "    all_datasets[\"nllb_back_translated\"] + \n",
    "    all_datasets[\"seamless_m4t_back_translated\"],\n",
    "    ignore_index=True  # Reset index to avoid duplicates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to prevent order bias\n",
    "combined_data = combined_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1627576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the correspondent must be given a different rate.</td>\n",
       "      <td>စာပို့သူကိုနှုန်း ကွာခြားချက်တစ်ခု ပေးအပ်ရပါမယ်။</td>\n",
       "      <td>['▁the', '▁correspond', 'ent', '▁must', '▁be',...</td>\n",
       "      <td>['▁စာပို့', 'သူကို', 'နှုန်း', '▁ကွာခြား', 'ချ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>octopi can be found in tiny crevices in the me...</td>\n",
       "      <td>Octopi ကို မြေထဲပင်လယ်ရှိ သေးငယ်သော အပေါက်များ...</td>\n",
       "      <td>['▁oct', 'op', 'i', '▁can', '▁be', '▁found', '...</td>\n",
       "      <td>['▁O', 'ct', 'op', 'i', '▁ကို', '▁မြေထဲပင်လယ်'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the model shows where we can cut costs most ef...</td>\n",
       "      <td>မော်ဒယ်သည် ကုန်ကျစရိတ်များကို အထိရောက်ဆုံး လျှ...</td>\n",
       "      <td>['▁the', '▁model', '▁shows', '▁where', '▁we', ...</td>\n",
       "      <td>['▁မော်ဒယ်', 'သည်', '▁ကုန်ကျစရိတ်', 'များကို',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he always wanted to be a journalist.</td>\n",
       "      <td>သူဟာ သတင်းစာသမားဖြစ်ချင်ခဲ့တာ အမြဲတမ်းပါ။</td>\n",
       "      <td>['▁he', '▁always', '▁wanted', '▁to', '▁be', '▁...</td>\n",
       "      <td>['▁သူဟာ', '▁သတင်းစာ', 'သမား', 'ဖြစ်', 'ချင်', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the oldest rooms are near the western gate, an...</td>\n",
       "      <td>ရှေးအကျဆုံး အခန်းတွေဟာ အနောက်ဘက် တံခါးနားမှာရှ...</td>\n",
       "      <td>['▁the', '▁oldest', '▁rooms', '▁are', '▁near',...</td>\n",
       "      <td>['▁ရှေးအကျဆုံး', '▁အခန်းတွေဟာ', '▁အနောက်ဘက်', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the correspondent must be given a different rate.   \n",
       "1  octopi can be found in tiny crevices in the me...   \n",
       "2  the model shows where we can cut costs most ef...   \n",
       "3               he always wanted to be a journalist.   \n",
       "4  the oldest rooms are near the western gate, an...   \n",
       "\n",
       "                                             burmese  \\\n",
       "0   စာပို့သူကိုနှုန်း ကွာခြားချက်တစ်ခု ပေးအပ်ရပါမယ်။   \n",
       "1  Octopi ကို မြေထဲပင်လယ်ရှိ သေးငယ်သော အပေါက်များ...   \n",
       "2  မော်ဒယ်သည် ကုန်ကျစရိတ်များကို အထိရောက်ဆုံး လျှ...   \n",
       "3          သူဟာ သတင်းစာသမားဖြစ်ချင်ခဲ့တာ အမြဲတမ်းပါ။   \n",
       "4  ရှေးအကျဆုံး အခန်းတွေဟာ အနောက်ဘက် တံခါးနားမှာရှ...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['▁the', '▁correspond', 'ent', '▁must', '▁be',...   \n",
       "1  ['▁oct', 'op', 'i', '▁can', '▁be', '▁found', '...   \n",
       "2  ['▁the', '▁model', '▁shows', '▁where', '▁we', ...   \n",
       "3  ['▁he', '▁always', '▁wanted', '▁to', '▁be', '▁...   \n",
       "4  ['▁the', '▁oldest', '▁rooms', '▁are', '▁near',...   \n",
       "\n",
       "                                      burmese_tokens  \n",
       "0  ['▁စာပို့', 'သူကို', 'နှုန်း', '▁ကွာခြား', 'ချ...  \n",
       "1  ['▁O', 'ct', 'op', 'i', '▁ကို', '▁မြေထဲပင်လယ်'...  \n",
       "2  ['▁မော်ဒယ်', 'သည်', '▁ကုန်ကျစရိတ်', 'များကို',...  \n",
       "3  ['▁သူဟာ', '▁သတင်းစာ', 'သမား', 'ဖြစ်', 'ချင်', ...  \n",
       "4  ['▁ရှေးအကျဆုံး', '▁အခန်းတွေဟာ', '▁အနောက်ဘက်', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(combined_data)}\")\n",
    "display(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined datasets\n",
    "save_models_df(combined_data, \"combined_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing RNN/LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SentencePiece BPE tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spt/spt_bpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load combined data\n",
    "lstm_preprocess_data = load_models_df(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943966fefec84eca96f5bef42c0e46b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1627576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d20b599e84eb4b5ec9625c482e131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1627576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>burmese_seq</th>\n",
       "      <th>english_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the correspondent must be given a different rate.</td>\n",
       "      <td>စာပို့သူကိုနှုန်း ကွာခြားချက်တစ်ခု ပေးအပ်ရပါမယ်။</td>\n",
       "      <td>['▁the', '▁correspond', 'ent', '▁must', '▁be',...</td>\n",
       "      <td>['▁စာပို့', 'သူကို', 'နှုန်း', '▁ကွာခြား', 'ချ...</td>\n",
       "      <td>[8777, 30887, 2847, 30887, 30883, 1519, 5855, ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 18489, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>octopi can be found in tiny crevices in the me...</td>\n",
       "      <td>Octopi ကို မြေထဲပင်လယ်ရှိ သေးငယ်သော အပေါက်များ...</td>\n",
       "      <td>['▁oct', 'op', 'i', '▁can', '▁be', '▁found', '...</td>\n",
       "      <td>['▁O', 'ct', 'op', 'i', '▁ကို', '▁မြေထဲပင်လယ်'...</td>\n",
       "      <td>[8777, 30887, 1602, 30887, 30883, 1519, 283, 3...</td>\n",
       "      <td>[8777, 30887, 8904, 30887, 30883, 1519, 221, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the model shows where we can cut costs most ef...</td>\n",
       "      <td>မော်ဒယ်သည် ကုန်ကျစရိတ်များကို အထိရောက်ဆုံး လျှ...</td>\n",
       "      <td>['▁the', '▁model', '▁shows', '▁where', '▁we', ...</td>\n",
       "      <td>['▁မော်ဒယ်', 'သည်', '▁ကုန်ကျစရိတ်', 'များကို',...</td>\n",
       "      <td>[8777, 30887, 7224, 30887, 30883, 1519, 68, 30...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 4047, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he always wanted to be a journalist.</td>\n",
       "      <td>သူဟာ သတင်းစာသမားဖြစ်ချင်ခဲ့တာ အမြဲတမ်းပါ။</td>\n",
       "      <td>['▁he', '▁always', '▁wanted', '▁to', '▁be', '▁...</td>\n",
       "      <td>['▁သူဟာ', '▁သတင်းစာ', 'သမား', 'ဖြစ်', 'ချင်', ...</td>\n",
       "      <td>[8777, 30887, 1499, 30887, 30883, 1519, 3143, ...</td>\n",
       "      <td>[8777, 30887, 153, 30887, 30883, 1519, 1321, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the oldest rooms are near the western gate, an...</td>\n",
       "      <td>ရှေးအကျဆုံး အခန်းတွေဟာ အနောက်ဘက် တံခါးနားမှာရှ...</td>\n",
       "      <td>['▁the', '▁oldest', '▁rooms', '▁are', '▁near',...</td>\n",
       "      <td>['▁ရှေးအကျဆုံး', '▁အခန်းတွေဟာ', '▁အနောက်ဘက်', ...</td>\n",
       "      <td>[8777, 30887, 14623, 30887, 30883, 1519, 29639...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 8573, 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the correspondent must be given a different rate.   \n",
       "1  octopi can be found in tiny crevices in the me...   \n",
       "2  the model shows where we can cut costs most ef...   \n",
       "3               he always wanted to be a journalist.   \n",
       "4  the oldest rooms are near the western gate, an...   \n",
       "\n",
       "                                             burmese  \\\n",
       "0   စာပို့သူကိုနှုန်း ကွာခြားချက်တစ်ခု ပေးအပ်ရပါမယ်။   \n",
       "1  Octopi ကို မြေထဲပင်လယ်ရှိ သေးငယ်သော အပေါက်များ...   \n",
       "2  မော်ဒယ်သည် ကုန်ကျစရိတ်များကို အထိရောက်ဆုံး လျှ...   \n",
       "3          သူဟာ သတင်းစာသမားဖြစ်ချင်ခဲ့တာ အမြဲတမ်းပါ။   \n",
       "4  ရှေးအကျဆုံး အခန်းတွေဟာ အနောက်ဘက် တံခါးနားမှာရှ...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['▁the', '▁correspond', 'ent', '▁must', '▁be',...   \n",
       "1  ['▁oct', 'op', 'i', '▁can', '▁be', '▁found', '...   \n",
       "2  ['▁the', '▁model', '▁shows', '▁where', '▁we', ...   \n",
       "3  ['▁he', '▁always', '▁wanted', '▁to', '▁be', '▁...   \n",
       "4  ['▁the', '▁oldest', '▁rooms', '▁are', '▁near',...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['▁စာပို့', 'သူကို', 'နှုန်း', '▁ကွာခြား', 'ချ...   \n",
       "1  ['▁O', 'ct', 'op', 'i', '▁ကို', '▁မြေထဲပင်လယ်'...   \n",
       "2  ['▁မော်ဒယ်', 'သည်', '▁ကုန်ကျစရိတ်', 'များကို',...   \n",
       "3  ['▁သူဟာ', '▁သတင်းစာ', 'သမား', 'ဖြစ်', 'ချင်', ...   \n",
       "4  ['▁ရှေးအကျဆုံး', '▁အခန်းတွေဟာ', '▁အနောက်ဘက်', ...   \n",
       "\n",
       "                                         burmese_seq  \\\n",
       "0  [8777, 30887, 2847, 30887, 30883, 1519, 5855, ...   \n",
       "1  [8777, 30887, 1602, 30887, 30883, 1519, 283, 3...   \n",
       "2  [8777, 30887, 7224, 30887, 30883, 1519, 68, 30...   \n",
       "3  [8777, 30887, 1499, 30887, 30883, 1519, 3143, ...   \n",
       "4  [8777, 30887, 14623, 30887, 30883, 1519, 29639...   \n",
       "\n",
       "                                         english_seq  \n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 18489, 3...  \n",
       "1  [8777, 30887, 8904, 30887, 30883, 1519, 221, 3...  \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 4047, 30...  \n",
       "3  [8777, 30887, 153, 30887, 30883, 1519, 1321, 3...  \n",
       "4  [8777, 30887, 12, 30887, 30883, 1519, 8573, 30...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tokenized sequences into lists\n",
    "lstm_preprocess_data[\"burmese_seq\"] = lstm_preprocess_data[\"burmese_tokens\"].progress_apply(\n",
    "    lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else []\n",
    ")\n",
    "lstm_preprocess_data[\"english_seq\"] = lstm_preprocess_data[\"english_tokens\"].progress_apply(\n",
    "    lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "display(lstm_preprocess_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum sequence length\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply padding\n",
    "lstm_preprocess_data[\"burmese_seq_padded\"] = pad_sequences(\n",
    "    lstm_preprocess_data[\"burmese_seq\"], maxlen=max_seq_length, padding=\"post\"\n",
    ").tolist()\n",
    "lstm_preprocess_data[\"english_seq_padded\"] = pad_sequences(\n",
    "    lstm_preprocess_data[\"english_seq\"], maxlen=max_seq_length, padding=\"post\"\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lstm preprocess data\n",
    "save_models_df(lstm_preprocess_data, \"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Model\n",
    "Define an LSTM-based sequence-to-sequence (seq2seq) model with embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lstm_embedding_dim = 256\n",
    "lstm_hidden_dim = 512\n",
    "lstm_vocab_size = sp.GetPieceSize()  # Get vocabulary size from SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):  \n",
    "    lstm_model = Sequential([\n",
    "        Embedding(input_dim=lstm_vocab_size, output_dim=lstm_embedding_dim, input_length=max_seq_length, mask_zero=True),\n",
    "        Bidirectional(LSTM(lstm_hidden_dim, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        LSTM(lstm_hidden_dim, return_sequences=False, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(lstm_vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display Model Summary\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Train the model using Categorical Cross-Entropy loss & Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LSTM preprocess data\n",
    "lstm_data = load_models_df(\"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "X_train = np.array(lstm_data[\"burmese_seq_padded\"].tolist())\n",
    "y_train = np.array(lstm_data[\"english_seq_padded\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):  \n",
    "    lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lstm model\n",
    "lstm_model.save(\"models/lstm_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model with BLEU Score\n",
    "Compute BLEU, ROUGE, and Perplexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LSTM preprocess data\n",
    "lstm_evaluation_results = load_models_df(\"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute bleu score\n",
    "def compute_bleu_lstm(reference, prediction):\n",
    "    return sentence_bleu([reference.split()], prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "lstm_evaluation_results[\"generated_lstm\"] = lstm_evaluation_results[\"burmese\"].progress_apply(\n",
    "    lambda x: \" \".join(sp.EncodeAsPieces(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU scores\n",
    "lstm_evaluation_results[\"bleu_lstm\"] = lstm_evaluation_results.progress_apply(\n",
    "    lambda row: compute_bleu_lstm(row[\"english\"], row[\"generated_lstm\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BLEU score results\n",
    "print(f\"LSTM BLEU Score: {lstm_evaluation_results['bleu_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE scores\n",
    "lstm_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_evaluation_results[\"rouge_lstm\"] = lstm_evaluation_results.progress_apply(\n",
    "    lambda row: lstm_scorer.score(row[\"english\"], row[\"generated_lstm\"])[\"rougeL\"].fmeasure, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROUGE score results\n",
    "print(f\"LSTM ROUGE Score: {lstm_evaluation_results['rouge_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_lstm(text, model_name=\"bert-base-multilingual-cased\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    log_likelihood = F.log_softmax(outputs.logits, dim=-1)\n",
    "    perplexity = torch.exp(-log_likelihood.mean()).item()\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity for LSTM-generated text\n",
    "lstm_evaluation_results[\"perplexity_lstm\"] = lstm_evaluation_results[\"generated_lstm\"].progress_apply(\n",
    "    lambda x: compute_perplexity_lstm(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Perplexity Score Results\n",
    "print(f\"LSTM Perplexity Score: {lstm_evaluation_results['perplexity_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_df(lstm_evaluation_results, \"lstm_evaluation_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing Multilingual Transformer Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Models\n",
    "Load ```mBERT``` and ```XLM-R``` for Masked Language Modeling (MLM).\n",
    "MLM helps predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model names\n",
    "multilingual_model_names = {\n",
    "    \"mBERT\": \"bert-base-multilingual-cased\",\n",
    "    \"XLM-R\": \"xlm-roberta-base\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for both mBERT and XLM-R\n",
    "multilingual_tokenizers = {\n",
    "    name: AutoTokenizer.from_pretrained(model) for name, model in multilingual_model_names.items()\n",
    "}\n",
    "multilingual_models = {\n",
    "    name: AutoModelForMaskedLM.from_pretrained(model).to(device) for name, model in multilingual_model_names.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed dataset\n",
    "mBERT_XLMR_evaludation_results = load_models_df(\"combined_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference Without Fine-Tuning\n",
    "Pass Burmese text through ```mBERT``` & ```XLM-R``` using Masked Language Modeling (MLM). mBERT/XLM-R predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate masked predictions\n",
    "def generate_masked_predictions(text, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Mask a random token in the sequence\n",
    "    mask_idx = torch.randint(1, inputs[\"input_ids\"].shape[1] - 1, (1,))\n",
    "    inputs[\"input_ids\"][0, mask_idx] = tokenizer.mask_token_id  # Replace one token with [MASK]\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get highest probability prediction for the masked token\n",
    "    predicted_token_id = torch.argmax(outputs.logits[0, mask_idx], dim=-1).item()\n",
    "    predicted_token = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "    return text.replace(tokenizer.mask_token, predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample Burmese sentences\n",
    "multilingual_sample_texts = mBERT_XLMR_evaludation_results[\"burmese\"].sample(5).tolist()\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for text in multilingual_sample_texts:\n",
    "        print(f\"Original: {text}\")\n",
    "        print(f\"Generated: {generate_masked_predictions(text, model_name)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Compare BLEU, ROUGE, and Perplexity scores between ```mBERT``` and ```XLM-R```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute BLEU score\n",
    "def compute_bleu_multilingual(reference, prediction):\n",
    "    return sentence_bleu([reference.split()], prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on dataset\n",
    "for model_name in multilingual_model_names:\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_generated\"] = mBERT_XLMR_evaludation_results[\"burmese\"].process_apply(\n",
    "        lambda x: generate_masked_predictions(x, model_name)\n",
    "    )\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_bleu\"] = mBERT_XLMR_evaludation_results.process_apply(\n",
    "        lambda row: compute_bleu_multilingual(row[\"english\"], row[f\"{model_name}_generated\"]), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BLEU scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} BLEU Score: {mBERT_XLMR_evaludation_results[f'{model_name}_bleu'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE Score\n",
    "multilingual_rouge_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "for model_name in multilingual_model_names:\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_rouge\"] = mBERT_XLMR_evaludation_results.process_apply(\n",
    "        lambda row: multilingual_rouge_scorer.score(row[\"english\"], row[f\"{model_name}_generated\"])[\"rougeL\"].fmeasure, axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROUGE scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} ROUGE Score: {mBERT_XLMR_evaludation_results[f'{model_name}_rouge'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute perplexity\n",
    "def compute_perplexity_multilingual(text, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = F.log_softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Compute Perplexity\n",
    "    perplexity = torch.exp(-log_likelihood.mean()).item()\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity for both models\n",
    "for model_name in multilingual_model_names:\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_perplexity\"] = mBERT_XLMR_evaludation_results[f\"{model_name}_generated\"].process_apply(\n",
    "        lambda x: compute_perplexity_multilingual(x, model_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Perplexity scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} Perplexity Score: {compute_perplexity_multilingual[f'{model_name}_perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_models_df(mBERT_XLMR_evaludation_results, \"mBERT_XLMR_evaludation_results\")\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Benchmarking and Analysis\n",
    "Compare the performance of LSTM, mBERT, and XLM-R using BLEU, ROUGE, and Perplexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
