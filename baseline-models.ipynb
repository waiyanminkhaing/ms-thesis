{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence_transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save models df\n",
    "def save_models_df(df, df_name):\n",
    "    df.to_csv(f\"models/{df_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load spt df\n",
    "def load_spt_df(df_name):\n",
    "    return pd.read_csv(f\"spt/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing RNN/LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SentencePiece BPE tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spt/spt_bpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Before training our RNN/LSTM model, we need to load, process, and prepare the dataset. This step ensures that our input data is structured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Tokenized Sentences \n",
    "Load BPE tokenized datasets, convert tokens into sequences, and apply padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "english_columns = [\n",
    "     \"english_tokens\"\n",
    "    ,\"english_back_translated_tokens\"\n",
    "]\n",
    "burmese_columns = [\n",
    "    \"burmese_tokens\"\n",
    "    ,\"burmese_translated_tokens\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and file paths\n",
    "datasets = {\n",
    "    \"normal\": [\n",
    "        \"tokenized_bpe_myxnli_normalized_1\", \n",
    "        \"tokenized_bpe_myxnli_normalized_2\", \n",
    "        \"tokenized_bpe_alt_combined_normalized\"\n",
    "    ],\n",
    "    \"nllb_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_1\", \n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_2\", \n",
    "        \"tokenized_bpe_alt_combined_nllb_back_translated_final\"\n",
    "    ],\n",
    "    \"seamless_m4t_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_1\",\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_2\",\n",
    "        \"tokenized_bpe_alt_combined_seamless_m4t_back_translated_final\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "def rename_columns(df):\n",
    "    column_mapping = {\n",
    "        \"english_back_translated\": \"english\",\n",
    "        \"burmese_translated\": \"burmese\",\n",
    "        \"english_back_translated_tokens\": \"english_tokens\",\n",
    "        \"burmese_translated_tokens\": \"burmese_tokens\",\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ensure only required columns exist\n",
    "    df = df[[\"english\", \"burmese\", \"english_tokens\", \"burmese_tokens\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "def load_and_process_dataset(file_name):\n",
    "    df = load_spt_df(f\"{file_name}\")\n",
    "\n",
    "    # Rename columns\n",
    "    df = rename_columns(df)\n",
    "\n",
    "    for column in english_columns:\n",
    "        if column in df.columns:\n",
    "            df[\"english_seq\"] = df[column].apply(lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else [])\n",
    "\n",
    "    for column in burmese_columns:\n",
    "        if column in df.columns:\n",
    "            df[\"burmese_seq\"] = df[column].apply(lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else [])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "processed_datasets = {\n",
    "    key: [load_and_process_dataset(file) for file in file_list] for key, file_list in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "full_data = pd.concat(\n",
    "    processed_datasets[\"normal\"] + \n",
    "    processed_datasets[\"nllb_back_translated\"] + \n",
    "    processed_datasets[\"seamless_m4t_back_translated\"],\n",
    "    ignore_index=True  # Reset index to avoid duplicates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to prevent order bias\n",
    "full_data = full_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1627576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>english_seq</th>\n",
       "      <th>burmese_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the palace is empty except for antiquities and...</td>\n",
       "      <td>နန်းတော်မှာ ရှေးဟောင်းပစ္စည်းတွေနဲ့ အခန်းလေးခန...</td>\n",
       "      <td>['▁the', '▁palace', '▁is', '▁empty', '▁except'...</td>\n",
       "      <td>['▁နန်းတော်', 'မှာ', '▁ရှေးဟောင်း', 'ပစ္စည်းတွ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these things are all thought of as classic fra...</td>\n",
       "      <td>ဤအရာအားလုံးကို ပြင်သစ်ဂန္ထဝင်အဖြစ် ယူဆထားသည်။</td>\n",
       "      <td>['▁these', '▁things', '▁are', '▁all', '▁though...</td>\n",
       "      <td>['▁ဤအရာ', 'အားလုံးကို', '▁ပြင်သစ်', 'ဂ', 'န္',...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal government's monetary budget proce...</td>\n",
       "      <td>ပြည်ထောင်စုအစိုးရရဲ့ ငွေကြေးအခြေခံ ဘတ်ဂျက်လုပ်...</td>\n",
       "      <td>['▁the', '▁federal', '▁government', \"'\", 's', ...</td>\n",
       "      <td>['▁ပြည်ထောင်စု', 'အစိုးရရဲ့', '▁ငွေကြေး', 'အခြ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1707, 30...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the house was huge.</td>\n",
       "      <td>အိမ်က ကြီးမားခဲ့တယ်။</td>\n",
       "      <td>['▁the', '▁house', '▁was', '▁huge', '.']</td>\n",
       "      <td>['▁အိမ်က', '▁ကြီးမား', 'ခဲ့တယ်။']</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you won't find a single spice shop on ibiza.</td>\n",
       "      <td>Ibiza မှာ ဟင်းခတ်အမွှေးအကြိုင်ဆိုင် တစ်ခုမှ မတ...</td>\n",
       "      <td>['▁you', '▁won', \"'\", 't', '▁find', '▁a', '▁si...</td>\n",
       "      <td>['▁Ibiza', '▁မှာ', '▁ဟင်းခတ်', 'အမွှေးအကြိုင်'...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the palace is empty except for antiquities and...   \n",
       "1  these things are all thought of as classic fra...   \n",
       "2  the federal government's monetary budget proce...   \n",
       "3                                the house was huge.   \n",
       "4       you won't find a single spice shop on ibiza.   \n",
       "\n",
       "                                             burmese  \\\n",
       "0  နန်းတော်မှာ ရှေးဟောင်းပစ္စည်းတွေနဲ့ အခန်းလေးခန...   \n",
       "1      ဤအရာအားလုံးကို ပြင်သစ်ဂန္ထဝင်အဖြစ် ယူဆထားသည်။   \n",
       "2  ပြည်ထောင်စုအစိုးရရဲ့ ငွေကြေးအခြေခံ ဘတ်ဂျက်လုပ်...   \n",
       "3                               အိမ်က ကြီးမားခဲ့တယ်။   \n",
       "4  Ibiza မှာ ဟင်းခတ်အမွှေးအကြိုင်ဆိုင် တစ်ခုမှ မတ...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['▁the', '▁palace', '▁is', '▁empty', '▁except'...   \n",
       "1  ['▁these', '▁things', '▁are', '▁all', '▁though...   \n",
       "2  ['▁the', '▁federal', '▁government', \"'\", 's', ...   \n",
       "3           ['▁the', '▁house', '▁was', '▁huge', '.']   \n",
       "4  ['▁you', '▁won', \"'\", 't', '▁find', '▁a', '▁si...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['▁နန်းတော်', 'မှာ', '▁ရှေးဟောင်း', 'ပစ္စည်းတွ...   \n",
       "1  ['▁ဤအရာ', 'အားလုံးကို', '▁ပြင်သစ်', 'ဂ', 'န္',...   \n",
       "2  ['▁ပြည်ထောင်စု', 'အစိုးရရဲ့', '▁ငွေကြေး', 'အခြ...   \n",
       "3                  ['▁အိမ်က', '▁ကြီးမား', 'ခဲ့တယ်။']   \n",
       "4  ['▁Ibiza', '▁မှာ', '▁ဟင်းခတ်', 'အမွှေးအကြိုင်'...   \n",
       "\n",
       "                                         english_seq  \\\n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...   \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...   \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 1707, 30...   \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...   \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...   \n",
       "\n",
       "                                         burmese_seq  \n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...  \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...  \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...  \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...  \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(full_data)}\")\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Padding to Sequences\n",
    "Ensure that all sequences have the same length for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust based on dataset analysis\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences padded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>english_seq</th>\n",
       "      <th>burmese_seq</th>\n",
       "      <th>burmese_seq_padded</th>\n",
       "      <th>english_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the palace is empty except for antiquities and...</td>\n",
       "      <td>နန်းတော်မှာ ရှေးဟောင်းပစ္စည်းတွေနဲ့ အခန်းလေးခန...</td>\n",
       "      <td>['▁the', '▁palace', '▁is', '▁empty', '▁except'...</td>\n",
       "      <td>['▁နန်းတော်', 'မှာ', '▁ရှေးဟောင်း', 'ပစ္စည်းတွ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these things are all thought of as classic fra...</td>\n",
       "      <td>ဤအရာအားလုံးကို ပြင်သစ်ဂန္ထဝင်အဖြစ် ယူဆထားသည်။</td>\n",
       "      <td>['▁these', '▁things', '▁are', '▁all', '▁though...</td>\n",
       "      <td>['▁ဤအရာ', 'အားလုံးကို', '▁ပြင်သစ်', 'ဂ', 'န္',...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal government's monetary budget proce...</td>\n",
       "      <td>ပြည်ထောင်စုအစိုးရရဲ့ ငွေကြေးအခြေခံ ဘတ်ဂျက်လုပ်...</td>\n",
       "      <td>['▁the', '▁federal', '▁government', \"'\", 's', ...</td>\n",
       "      <td>['▁ပြည်ထောင်စု', 'အစိုးရရဲ့', '▁ငွေကြေး', 'အခြ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1707, 30...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "      <td>[30887, 30883, 1519, 1707, 30887, 30883, 1519,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the house was huge.</td>\n",
       "      <td>အိမ်က ကြီးမားခဲ့တယ်။</td>\n",
       "      <td>['▁the', '▁house', '▁was', '▁huge', '.']</td>\n",
       "      <td>['▁အိမ်က', '▁ကြီးမား', 'ခဲ့တယ်။']</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you won't find a single spice shop on ibiza.</td>\n",
       "      <td>Ibiza မှာ ဟင်းခတ်အမွှေးအကြိုင်ဆိုင် တစ်ခုမှ မတ...</td>\n",
       "      <td>['▁you', '▁won', \"'\", 't', '▁find', '▁a', '▁si...</td>\n",
       "      <td>['▁Ibiza', '▁မှာ', '▁ဟင်းခတ်', 'အမွှေးအကြိုင်'...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the palace is empty except for antiquities and...   \n",
       "1  these things are all thought of as classic fra...   \n",
       "2  the federal government's monetary budget proce...   \n",
       "3                                the house was huge.   \n",
       "4       you won't find a single spice shop on ibiza.   \n",
       "\n",
       "                                             burmese  \\\n",
       "0  နန်းတော်မှာ ရှေးဟောင်းပစ္စည်းတွေနဲ့ အခန်းလေးခန...   \n",
       "1      ဤအရာအားလုံးကို ပြင်သစ်ဂန္ထဝင်အဖြစ် ယူဆထားသည်။   \n",
       "2  ပြည်ထောင်စုအစိုးရရဲ့ ငွေကြေးအခြေခံ ဘတ်ဂျက်လုပ်...   \n",
       "3                               အိမ်က ကြီးမားခဲ့တယ်။   \n",
       "4  Ibiza မှာ ဟင်းခတ်အမွှေးအကြိုင်ဆိုင် တစ်ခုမှ မတ...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['▁the', '▁palace', '▁is', '▁empty', '▁except'...   \n",
       "1  ['▁these', '▁things', '▁are', '▁all', '▁though...   \n",
       "2  ['▁the', '▁federal', '▁government', \"'\", 's', ...   \n",
       "3           ['▁the', '▁house', '▁was', '▁huge', '.']   \n",
       "4  ['▁you', '▁won', \"'\", 't', '▁find', '▁a', '▁si...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['▁နန်းတော်', 'မှာ', '▁ရှေးဟောင်း', 'ပစ္စည်းတွ...   \n",
       "1  ['▁ဤအရာ', 'အားလုံးကို', '▁ပြင်သစ်', 'ဂ', 'န္',...   \n",
       "2  ['▁ပြည်ထောင်စု', 'အစိုးရရဲ့', '▁ငွေကြေး', 'အခြ...   \n",
       "3                  ['▁အိမ်က', '▁ကြီးမား', 'ခဲ့တယ်။']   \n",
       "4  ['▁Ibiza', '▁မှာ', '▁ဟင်းခတ်', 'အမွှေးအကြိုင်'...   \n",
       "\n",
       "                                         english_seq  \\\n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...   \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...   \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 1707, 30...   \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...   \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...   \n",
       "\n",
       "                                         burmese_seq  \\\n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...   \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...   \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...   \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...   \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...   \n",
       "\n",
       "                                  burmese_seq_padded  \\\n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...   \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...   \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...   \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...   \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...   \n",
       "\n",
       "                                  english_seq_padded  \n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...  \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...  \n",
       "2  [30887, 30883, 1519, 1707, 30887, 30883, 1519,...  \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...  \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply padding\n",
    "full_data[\"burmese_seq_padded\"] = pad_sequences(full_data[\"burmese_seq\"], maxlen=max_seq_length, padding=\"post\").tolist()\n",
    "full_data[\"english_seq_padded\"] = pad_sequences(full_data[\"english_seq\"], maxlen=max_seq_length, padding=\"post\").tolist()\n",
    "\n",
    "print(\"Sequences padded successfully!\")\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed data\n",
    "save_models_df(full_data, \"processed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Model\n",
    "Use a Bidirectional LSTM encoder-decoder with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "vocab_size = sp.GetPieceSize()  # Get vocabulary size from SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 12:40:46.000879: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-01-30 12:40:46.000945: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-01-30 12:40:46.000960: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-01-30 12:40:46.000996: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-30 12:40:46.001014: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "with tf.device('/GPU:0'):  # Explicitly assign to GPU if available\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True),\n",
    "        Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        LSTM(hidden_dim, return_sequences=False, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Train the model using full dataset (Normal + Back-Translated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed data\n",
    "processed_data = load_spt_df(\"processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(processed_data[\"burmese_seq_padded\"].tolist())\n",
    "y_train = np.array(processed_data[\"english_seq_padded\"].tolist())\n",
    "\n",
    "# Train on GPU\n",
    "with tf.device('/GPU:0'):  \n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model with BLEU Score\n",
    "Compute BLEU Score for translation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode tokenized text back to sentences\n",
    "def decode_sentence(tokenized_seq):\n",
    "    return sp.DecodeIds([int(token) for token in tokenized_seq if token > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions\n",
    "sample_inputs = X_train[:5]\n",
    "sample_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions back to text\n",
    "generated_sentences = [decode_sentence(seq) for seq in sample_outputs]\n",
    "reference_sentences = [decode_sentence(seq) for seq in y_train[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU Score\n",
    "bleu_scores = [sentence_bleu([ref.split()], gen.split()) for ref, gen in zip(reference_sentences, generated_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for i in range(5):\n",
    "    print(f\"Reference: {reference_sentences[i]}\")\n",
    "    print(f\"Generated: {generated_sentences[i]}\")\n",
    "    print(f\"BLEU Score: {bleu_scores[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Export Model\n",
    "Save trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/bpe_lstm_baseline_model.h5\")\n",
    "sp.Save(\"models/bpe_model_trained.model\")\n",
    "\n",
    "print(\"Model and tokenizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
