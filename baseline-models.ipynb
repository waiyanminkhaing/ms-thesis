{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence_transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sentencepiece as spm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from rouge_score import rouge_scorer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# for mac\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(\"GPU details: \", details)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# set GPU device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window / Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window\n",
    "print(\"Tensorflow GPUs: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using PyTorch device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save models df\n",
    "def save_models_df(df, df_name):\n",
    "    df.to_csv(f\"models/{df_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save tmp df\n",
    "def save_tmp_df(df, df_name):\n",
    "    df.to_csv(f\"tmp/{df_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load spt df\n",
    "def load_spt_df(df_name):\n",
    "    return pd.read_csv(f\"spt/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load models df\n",
    "def load_models_df(df_name):\n",
    "    return pd.read_csv(f\"models/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load tmp df\n",
    "def load_tmp_df(df_name):\n",
    "    return pd.read_csv(f\"tmp/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and file paths\n",
    "datasets = {\n",
    "    \"normal\": [\n",
    "        \"tokenized_bpe_myxnli_normalized_1\", \n",
    "        \"tokenized_bpe_myxnli_normalized_2\", \n",
    "        \"tokenized_bpe_alt_combined_normalized\"\n",
    "    ],\n",
    "    \"nllb_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_1\", \n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_2\", \n",
    "        \"tokenized_bpe_alt_combined_nllb_back_translated_final\"\n",
    "    ],\n",
    "    \"seamless_m4t_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_1\",\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_2\",\n",
    "        \"tokenized_bpe_alt_combined_seamless_m4t_back_translated_final\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "def load_and_rename_columns(file_name):\n",
    "    df = load_spt_df(f\"{file_name}\")\n",
    "\n",
    "    column_mapping = {\n",
    "        \"english_back_translated\": \"english\",\n",
    "        \"burmese_translated\": \"burmese\",\n",
    "        \"english_back_translated_tokens\": \"english_tokens\",\n",
    "        \"burmese_translated_tokens\": \"burmese_tokens\",\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ensure only required columns exist\n",
    "    df = df[[\"english\", \"burmese\", \"english_tokens\", \"burmese_tokens\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "all_datasets = {\n",
    "    key: [load_and_rename_columns(file) for file in file_list] for key, file_list in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "combined_data = pd.concat(\n",
    "    all_datasets[\"normal\"] + \n",
    "    all_datasets[\"nllb_back_translated\"] + \n",
    "    all_datasets[\"seamless_m4t_back_translated\"],\n",
    "    ignore_index=True  # Reset index to avoid duplicates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to prevent order bias\n",
    "combined_data = combined_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1627576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the correspondent must be given a different rate.</td>\n",
       "      <td>á€…á€¬á€•á€­á€¯á€·á€á€°á€€á€­á€¯á€”á€¾á€¯á€”á€ºá€¸ á€€á€½á€¬á€á€¼á€¬á€¸á€á€»á€€á€ºá€á€…á€ºá€á€¯ á€•á€±á€¸á€¡á€•á€ºá€›á€•á€«á€™á€šá€ºá‹</td>\n",
       "      <td>['â–the', 'â–correspond', 'ent', 'â–must', 'â–be',...</td>\n",
       "      <td>['â–á€…á€¬á€•á€­á€¯á€·', 'á€á€°á€€á€­á€¯', 'á€”á€¾á€¯á€”á€ºá€¸', 'â–á€€á€½á€¬á€á€¼á€¬á€¸', 'á€á€»...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>octopi can be found in tiny crevices in the me...</td>\n",
       "      <td>Octopi á€€á€­á€¯ á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€ºá€›á€¾á€­ á€á€±á€¸á€„á€šá€ºá€á€±á€¬ á€¡á€•á€±á€«á€€á€ºá€™á€»á€¬á€¸...</td>\n",
       "      <td>['â–oct', 'op', 'i', 'â–can', 'â–be', 'â–found', '...</td>\n",
       "      <td>['â–O', 'ct', 'op', 'i', 'â–á€€á€­á€¯', 'â–á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€º'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the model shows where we can cut costs most ef...</td>\n",
       "      <td>á€™á€±á€¬á€ºá€’á€šá€ºá€á€Šá€º á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€‘á€­á€›á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ á€œá€»á€¾...</td>\n",
       "      <td>['â–the', 'â–model', 'â–shows', 'â–where', 'â–we', ...</td>\n",
       "      <td>['â–á€™á€±á€¬á€ºá€’á€šá€º', 'á€á€Šá€º', 'â–á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€º', 'á€™á€»á€¬á€¸á€€á€­á€¯',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he always wanted to be a journalist.</td>\n",
       "      <td>á€á€°á€Ÿá€¬ á€á€á€„á€ºá€¸á€…á€¬á€á€™á€¬á€¸á€–á€¼á€…á€ºá€á€»á€„á€ºá€á€²á€·á€á€¬ á€¡á€™á€¼á€²á€á€™á€ºá€¸á€•á€«á‹</td>\n",
       "      <td>['â–he', 'â–always', 'â–wanted', 'â–to', 'â–be', 'â–...</td>\n",
       "      <td>['â–á€á€°á€Ÿá€¬', 'â–á€á€á€„á€ºá€¸á€…á€¬', 'á€á€™á€¬á€¸', 'á€–á€¼á€…á€º', 'á€á€»á€„á€º', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the oldest rooms are near the western gate, an...</td>\n",
       "      <td>á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸ á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬ á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º á€á€¶á€á€«á€¸á€”á€¬á€¸á€™á€¾á€¬á€›á€¾...</td>\n",
       "      <td>['â–the', 'â–oldest', 'â–rooms', 'â–are', 'â–near',...</td>\n",
       "      <td>['â–á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸', 'â–á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬', 'â–á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the correspondent must be given a different rate.   \n",
       "1  octopi can be found in tiny crevices in the me...   \n",
       "2  the model shows where we can cut costs most ef...   \n",
       "3               he always wanted to be a journalist.   \n",
       "4  the oldest rooms are near the western gate, an...   \n",
       "\n",
       "                                             burmese  \\\n",
       "0   á€…á€¬á€•á€­á€¯á€·á€á€°á€€á€­á€¯á€”á€¾á€¯á€”á€ºá€¸ á€€á€½á€¬á€á€¼á€¬á€¸á€á€»á€€á€ºá€á€…á€ºá€á€¯ á€•á€±á€¸á€¡á€•á€ºá€›á€•á€«á€™á€šá€ºá‹   \n",
       "1  Octopi á€€á€­á€¯ á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€ºá€›á€¾á€­ á€á€±á€¸á€„á€šá€ºá€á€±á€¬ á€¡á€•á€±á€«á€€á€ºá€™á€»á€¬á€¸...   \n",
       "2  á€™á€±á€¬á€ºá€’á€šá€ºá€á€Šá€º á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€‘á€­á€›á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ á€œá€»á€¾...   \n",
       "3          á€á€°á€Ÿá€¬ á€á€á€„á€ºá€¸á€…á€¬á€á€™á€¬á€¸á€–á€¼á€…á€ºá€á€»á€„á€ºá€á€²á€·á€á€¬ á€¡á€™á€¼á€²á€á€™á€ºá€¸á€•á€«á‹   \n",
       "4  á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸ á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬ á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º á€á€¶á€á€«á€¸á€”á€¬á€¸á€™á€¾á€¬á€›á€¾...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['â–the', 'â–correspond', 'ent', 'â–must', 'â–be',...   \n",
       "1  ['â–oct', 'op', 'i', 'â–can', 'â–be', 'â–found', '...   \n",
       "2  ['â–the', 'â–model', 'â–shows', 'â–where', 'â–we', ...   \n",
       "3  ['â–he', 'â–always', 'â–wanted', 'â–to', 'â–be', 'â–...   \n",
       "4  ['â–the', 'â–oldest', 'â–rooms', 'â–are', 'â–near',...   \n",
       "\n",
       "                                      burmese_tokens  \n",
       "0  ['â–á€…á€¬á€•á€­á€¯á€·', 'á€á€°á€€á€­á€¯', 'á€”á€¾á€¯á€”á€ºá€¸', 'â–á€€á€½á€¬á€á€¼á€¬á€¸', 'á€á€»...  \n",
       "1  ['â–O', 'ct', 'op', 'i', 'â–á€€á€­á€¯', 'â–á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€º'...  \n",
       "2  ['â–á€™á€±á€¬á€ºá€’á€šá€º', 'á€á€Šá€º', 'â–á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€º', 'á€™á€»á€¬á€¸á€€á€­á€¯',...  \n",
       "3  ['â–á€á€°á€Ÿá€¬', 'â–á€á€á€„á€ºá€¸á€…á€¬', 'á€á€™á€¬á€¸', 'á€–á€¼á€…á€º', 'á€á€»á€„á€º', ...  \n",
       "4  ['â–á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸', 'â–á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬', 'â–á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(combined_data)}\")\n",
    "display(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined datasets\n",
    "save_models_df(combined_data, \"combined_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing RNN/LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SentencePiece BPE tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spt/spt_bpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load combined data\n",
    "lstm_preprocess_data = load_models_df(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943966fefec84eca96f5bef42c0e46b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1627576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d20b599e84eb4b5ec9625c482e131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1627576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>burmese_seq</th>\n",
       "      <th>english_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the correspondent must be given a different rate.</td>\n",
       "      <td>á€…á€¬á€•á€­á€¯á€·á€á€°á€€á€­á€¯á€”á€¾á€¯á€”á€ºá€¸ á€€á€½á€¬á€á€¼á€¬á€¸á€á€»á€€á€ºá€á€…á€ºá€á€¯ á€•á€±á€¸á€¡á€•á€ºá€›á€•á€«á€™á€šá€ºá‹</td>\n",
       "      <td>['â–the', 'â–correspond', 'ent', 'â–must', 'â–be',...</td>\n",
       "      <td>['â–á€…á€¬á€•á€­á€¯á€·', 'á€á€°á€€á€­á€¯', 'á€”á€¾á€¯á€”á€ºá€¸', 'â–á€€á€½á€¬á€á€¼á€¬á€¸', 'á€á€»...</td>\n",
       "      <td>[8777, 30887, 2847, 30887, 30883, 1519, 5855, ...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 18489, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>octopi can be found in tiny crevices in the me...</td>\n",
       "      <td>Octopi á€€á€­á€¯ á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€ºá€›á€¾á€­ á€á€±á€¸á€„á€šá€ºá€á€±á€¬ á€¡á€•á€±á€«á€€á€ºá€™á€»á€¬á€¸...</td>\n",
       "      <td>['â–oct', 'op', 'i', 'â–can', 'â–be', 'â–found', '...</td>\n",
       "      <td>['â–O', 'ct', 'op', 'i', 'â–á€€á€­á€¯', 'â–á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€º'...</td>\n",
       "      <td>[8777, 30887, 1602, 30887, 30883, 1519, 283, 3...</td>\n",
       "      <td>[8777, 30887, 8904, 30887, 30883, 1519, 221, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the model shows where we can cut costs most ef...</td>\n",
       "      <td>á€™á€±á€¬á€ºá€’á€šá€ºá€á€Šá€º á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€‘á€­á€›á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ á€œá€»á€¾...</td>\n",
       "      <td>['â–the', 'â–model', 'â–shows', 'â–where', 'â–we', ...</td>\n",
       "      <td>['â–á€™á€±á€¬á€ºá€’á€šá€º', 'á€á€Šá€º', 'â–á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€º', 'á€™á€»á€¬á€¸á€€á€­á€¯',...</td>\n",
       "      <td>[8777, 30887, 7224, 30887, 30883, 1519, 68, 30...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 4047, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he always wanted to be a journalist.</td>\n",
       "      <td>á€á€°á€Ÿá€¬ á€á€á€„á€ºá€¸á€…á€¬á€á€™á€¬á€¸á€–á€¼á€…á€ºá€á€»á€„á€ºá€á€²á€·á€á€¬ á€¡á€™á€¼á€²á€á€™á€ºá€¸á€•á€«á‹</td>\n",
       "      <td>['â–he', 'â–always', 'â–wanted', 'â–to', 'â–be', 'â–...</td>\n",
       "      <td>['â–á€á€°á€Ÿá€¬', 'â–á€á€á€„á€ºá€¸á€…á€¬', 'á€á€™á€¬á€¸', 'á€–á€¼á€…á€º', 'á€á€»á€„á€º', ...</td>\n",
       "      <td>[8777, 30887, 1499, 30887, 30883, 1519, 3143, ...</td>\n",
       "      <td>[8777, 30887, 153, 30887, 30883, 1519, 1321, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the oldest rooms are near the western gate, an...</td>\n",
       "      <td>á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸ á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬ á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º á€á€¶á€á€«á€¸á€”á€¬á€¸á€™á€¾á€¬á€›á€¾...</td>\n",
       "      <td>['â–the', 'â–oldest', 'â–rooms', 'â–are', 'â–near',...</td>\n",
       "      <td>['â–á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸', 'â–á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬', 'â–á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º', ...</td>\n",
       "      <td>[8777, 30887, 14623, 30887, 30883, 1519, 29639...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 8573, 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the correspondent must be given a different rate.   \n",
       "1  octopi can be found in tiny crevices in the me...   \n",
       "2  the model shows where we can cut costs most ef...   \n",
       "3               he always wanted to be a journalist.   \n",
       "4  the oldest rooms are near the western gate, an...   \n",
       "\n",
       "                                             burmese  \\\n",
       "0   á€…á€¬á€•á€­á€¯á€·á€á€°á€€á€­á€¯á€”á€¾á€¯á€”á€ºá€¸ á€€á€½á€¬á€á€¼á€¬á€¸á€á€»á€€á€ºá€á€…á€ºá€á€¯ á€•á€±á€¸á€¡á€•á€ºá€›á€•á€«á€™á€šá€ºá‹   \n",
       "1  Octopi á€€á€­á€¯ á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€ºá€›á€¾á€­ á€á€±á€¸á€„á€šá€ºá€á€±á€¬ á€¡á€•á€±á€«á€€á€ºá€™á€»á€¬á€¸...   \n",
       "2  á€™á€±á€¬á€ºá€’á€šá€ºá€á€Šá€º á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€ºá€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€‘á€­á€›á€±á€¬á€€á€ºá€†á€¯á€¶á€¸ á€œá€»á€¾...   \n",
       "3          á€á€°á€Ÿá€¬ á€á€á€„á€ºá€¸á€…á€¬á€á€™á€¬á€¸á€–á€¼á€…á€ºá€á€»á€„á€ºá€á€²á€·á€á€¬ á€¡á€™á€¼á€²á€á€™á€ºá€¸á€•á€«á‹   \n",
       "4  á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸ á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬ á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º á€á€¶á€á€«á€¸á€”á€¬á€¸á€™á€¾á€¬á€›á€¾...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['â–the', 'â–correspond', 'ent', 'â–must', 'â–be',...   \n",
       "1  ['â–oct', 'op', 'i', 'â–can', 'â–be', 'â–found', '...   \n",
       "2  ['â–the', 'â–model', 'â–shows', 'â–where', 'â–we', ...   \n",
       "3  ['â–he', 'â–always', 'â–wanted', 'â–to', 'â–be', 'â–...   \n",
       "4  ['â–the', 'â–oldest', 'â–rooms', 'â–are', 'â–near',...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['â–á€…á€¬á€•á€­á€¯á€·', 'á€á€°á€€á€­á€¯', 'á€”á€¾á€¯á€”á€ºá€¸', 'â–á€€á€½á€¬á€á€¼á€¬á€¸', 'á€á€»...   \n",
       "1  ['â–O', 'ct', 'op', 'i', 'â–á€€á€­á€¯', 'â–á€™á€¼á€±á€‘á€²á€•á€„á€ºá€œá€šá€º'...   \n",
       "2  ['â–á€™á€±á€¬á€ºá€’á€šá€º', 'á€á€Šá€º', 'â–á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€º', 'á€™á€»á€¬á€¸á€€á€­á€¯',...   \n",
       "3  ['â–á€á€°á€Ÿá€¬', 'â–á€á€á€„á€ºá€¸á€…á€¬', 'á€á€™á€¬á€¸', 'á€–á€¼á€…á€º', 'á€á€»á€„á€º', ...   \n",
       "4  ['â–á€›á€¾á€±á€¸á€¡á€€á€»á€†á€¯á€¶á€¸', 'â–á€¡á€á€”á€ºá€¸á€á€½á€±á€Ÿá€¬', 'â–á€¡á€”á€±á€¬á€€á€ºá€˜á€€á€º', ...   \n",
       "\n",
       "                                         burmese_seq  \\\n",
       "0  [8777, 30887, 2847, 30887, 30883, 1519, 5855, ...   \n",
       "1  [8777, 30887, 1602, 30887, 30883, 1519, 283, 3...   \n",
       "2  [8777, 30887, 7224, 30887, 30883, 1519, 68, 30...   \n",
       "3  [8777, 30887, 1499, 30887, 30883, 1519, 3143, ...   \n",
       "4  [8777, 30887, 14623, 30887, 30883, 1519, 29639...   \n",
       "\n",
       "                                         english_seq  \n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 18489, 3...  \n",
       "1  [8777, 30887, 8904, 30887, 30883, 1519, 221, 3...  \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 4047, 30...  \n",
       "3  [8777, 30887, 153, 30887, 30883, 1519, 1321, 3...  \n",
       "4  [8777, 30887, 12, 30887, 30883, 1519, 8573, 30...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert tokenized sequences into lists\n",
    "lstm_preprocess_data[\"burmese_seq\"] = lstm_preprocess_data[\"burmese_tokens\"].progress_apply(\n",
    "    lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else []\n",
    ")\n",
    "lstm_preprocess_data[\"english_seq\"] = lstm_preprocess_data[\"english_tokens\"].progress_apply(\n",
    "    lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "display(lstm_preprocess_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define maximum sequence length\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply padding\n",
    "lstm_preprocess_data[\"burmese_seq_padded\"] = pad_sequences(\n",
    "    lstm_preprocess_data[\"burmese_seq\"], maxlen=max_seq_length, padding=\"post\"\n",
    ").tolist()\n",
    "lstm_preprocess_data[\"english_seq_padded\"] = pad_sequences(\n",
    "    lstm_preprocess_data[\"english_seq\"], maxlen=max_seq_length, padding=\"post\"\n",
    ").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lstm preprocess data\n",
    "save_models_df(lstm_preprocess_data, \"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Model\n",
    "Define an LSTM-based sequence-to-sequence (seq2seq) model with embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lstm_embedding_dim = 256\n",
    "lstm_hidden_dim = 512\n",
    "lstm_vocab_size = sp.GetPieceSize()  # Get vocabulary size from SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):  \n",
    "    lstm_model = Sequential([\n",
    "        Embedding(input_dim=lstm_vocab_size, output_dim=lstm_embedding_dim, input_length=max_seq_length, mask_zero=True),\n",
    "        Bidirectional(LSTM(lstm_hidden_dim, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        LSTM(lstm_hidden_dim, return_sequences=False, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(lstm_vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display Model Summary\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Train the model using Categorical Cross-Entropy loss & Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LSTM preprocess data\n",
    "lstm_data = load_models_df(\"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "X_train = np.array(lstm_data[\"burmese_seq_padded\"].tolist())\n",
    "y_train = np.array(lstm_data[\"english_seq_padded\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):  \n",
    "    lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lstm model\n",
    "lstm_model.save(\"models/lstm_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model with BLEU Score\n",
    "Compute BLEU, ROUGE, and Perplexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LSTM preprocess data\n",
    "lstm_evaluation_results = load_models_df(\"lstm_preprocess_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute bleu score\n",
    "def compute_bleu_lstm(reference, prediction):\n",
    "    return sentence_bleu([reference.split()], prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "lstm_evaluation_results[\"generated_lstm\"] = lstm_evaluation_results[\"burmese\"].progress_apply(\n",
    "    lambda x: \" \".join(sp.EncodeAsPieces(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU scores\n",
    "lstm_evaluation_results[\"bleu_lstm\"] = lstm_evaluation_results.progress_apply(\n",
    "    lambda row: compute_bleu_lstm(row[\"english\"], row[\"generated_lstm\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BLEU score results\n",
    "print(f\"LSTM BLEU Score: {lstm_evaluation_results['bleu_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE scores\n",
    "lstm_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_evaluation_results[\"rouge_lstm\"] = lstm_evaluation_results.progress_apply(\n",
    "    lambda row: lstm_scorer.score(row[\"english\"], row[\"generated_lstm\"])[\"rougeL\"].fmeasure, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROUGE score results\n",
    "print(f\"LSTM ROUGE Score: {lstm_evaluation_results['rouge_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_lstm(text, model_name=\"bert-base-multilingual-cased\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    log_likelihood = F.log_softmax(outputs.logits, dim=-1)\n",
    "    perplexity = torch.exp(-log_likelihood.mean()).item()\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity for LSTM-generated text\n",
    "lstm_evaluation_results[\"perplexity_lstm\"] = lstm_evaluation_results[\"generated_lstm\"].progress_apply(\n",
    "    lambda x: compute_perplexity_lstm(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Perplexity Score Results\n",
    "print(f\"LSTM Perplexity Score: {lstm_evaluation_results['perplexity_lstm'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_df(lstm_evaluation_results, \"lstm_evaluation_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing Multilingual Transformer Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Models\n",
    "Load ```mBERT``` and ```XLM-R``` for Masked Language Modeling (MLM).\n",
    "MLM helps predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model names\n",
    "multilingual_model_names = {\n",
    "    \"mBERT\": \"bert-base-multilingual-cased\",\n",
    "    \"XLM-R\": \"xlm-roberta-base\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizers & models for both mBERT and XLM-R\n",
    "multilingual_tokenizers = {\n",
    "    name: AutoTokenizer.from_pretrained(model) for name, model in multilingual_model_names.items()\n",
    "}\n",
    "multilingual_models = {\n",
    "    name: AutoModelForMaskedLM.from_pretrained(model).to(device) for name, model in multilingual_model_names.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed dataset\n",
    "mBERT_XLMR_evaludation_results = load_models_df(\"combined_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference Without Fine-Tuning\n",
    "Pass Burmese text through ```mBERT``` & ```XLM-R``` using Masked Language Modeling (MLM). mBERT/XLM-R predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate masked predictions\n",
    "def generate_masked_predictions_batch(texts, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name].to(device)\n",
    "    \n",
    "    # Ensure all inputs are strings, replace NaN/None with an empty string\n",
    "    valid_texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
    "    \n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(valid_texts, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Ensure at least 3 tokens (CLS + Masked + SEP)\n",
    "    seq_lengths = inputs[\"input_ids\"].shape[1]\n",
    "    mask_indices = [\n",
    "        torch.randint(1, seq_lengths - 1, (1,)).item() if seq_lengths > 2 else None\n",
    "        for _ in valid_texts\n",
    "    ]\n",
    "\n",
    "    # Apply masking\n",
    "    for i, idx in enumerate(mask_indices):\n",
    "        if idx is not None:\n",
    "            inputs[\"input_ids\"][i, idx] = tokenizer.mask_token_id  # Replace token with [MASK]\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get predicted tokens\n",
    "    predicted_tokens = []\n",
    "    for i, idx in enumerate(mask_indices):\n",
    "        if idx is not None:\n",
    "            predicted_token_id = torch.argmax(outputs.logits[i, idx], dim=-1).item()\n",
    "            predicted_token = tokenizer.decode([predicted_token_id])\n",
    "            predicted_tokens.append(predicted_token)\n",
    "        else:\n",
    "            predicted_tokens.append(valid_texts[i])  # Return original text if no masking was possible\n",
    "\n",
    "    # Replace [MASK] with predicted tokens\n",
    "    masked_replaced_texts = [\n",
    "        text.replace(tokenizer.mask_token, pred) if tokenizer.mask_token in text else text\n",
    "        for text, pred in zip(valid_texts, predicted_tokens)\n",
    "    ]\n",
    "\n",
    "    return masked_replaced_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mBERT\n",
      "Original: á€’á€«á€Ÿá€¬ á€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯á€á€…á€ºá€á€¯á€•á€«á‹ á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€‘á€¬á€á€…á€‰á€ºá€‘á€±á€¬á€„á€ºá€’á€á€ºá€á€»á€™á€¾á€á€ºá€á€„á€·á€ºá€á€œá€±á€¬ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€¡á€–á€½á€²á€·á€¡á€…á€Šá€ºá€¸á€–á€½á€²á€·á€…á€Šá€ºá€¸á€€á€¬ á€•á€¼á€¯á€•á€¼á€„á€ºá€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€›á€”á€º á€€á€¼á€­á€¯á€¸á€•á€™á€ºá€¸á€á€„á€·á€ºá€•á€«á€á€œá€¬á€¸á‹\n",
      "Generated: á€’á€«á€Ÿá€¬ á€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯á€á€…á€ºá€á€¯á€•á€«á‹ á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€‘á€¬á€á€…á€‰á€ºá€‘á€±á€¬á€„á€ºá€’á€á€ºá€á€»á€™á€¾á€á€ºá€á€„á€·á€ºá€á€œá€±á€¬ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€¡á€–á€½á€²á€·á€¡á€…á€Šá€ºá€¸á€–á€½á€²á€·á€…á€Šá€ºá€¸á€€á€¬ á€•á€¼á€¯á€•á€¼á€„á€ºá€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€›á€”á€º á€€á€¼á€­á€¯á€¸á€•á€™á€ºá€¸á€á€„á€·á€ºá€•á€«á€á€œá€¬á€¸á‹\n",
      "\n",
      "Original: á€¡á€›á€±á€¬á€„á€ºá€¸á€€á€½á€„á€ºá€¸á€á€Šá€º á€¡á€œá€¯á€•á€ºá€á€™á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€”á€¹á€á€›á€¬á€šá€ºá€–á€¼á€…á€ºá€…á€±á€›á€”á€º á€’á€®á€‡á€­á€¯á€„á€ºá€¸á€‘á€¯á€á€ºá€‘á€¬á€¸á€á€Šá€ºá‹\n",
      "Generated: á€¡á€›á€±á€¬á€„á€ºá€¸á€€á€½á€„á€ºá€¸á€á€Šá€º á€¡á€œá€¯á€•á€ºá€á€™á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€”á€¹á€á€›á€¬á€šá€ºá€–á€¼á€…á€ºá€…á€±á€›á€”á€º á€’á€®á€‡á€­á€¯á€„á€ºá€¸á€‘á€¯á€á€ºá€‘á€¬á€¸á€á€Šá€ºá‹\n",
      "\n",
      "Original: á€¡á€‘á€°á€¸á€á€–á€¼á€„á€·á€º Tuppence á€€ á€šá€¬á€‰á€ºá€™á€±á€¬á€„á€ºá€¸á€€á€­á€¯ á€•á€¼á€±á€¬á€á€²á€·á€á€šá€ºá‹\n",
      "Generated: á€¡á€‘á€°á€¸á€á€–á€¼á€„á€·á€º Tuppence á€€ á€šá€¬á€‰á€ºá€™á€±á€¬á€„á€ºá€¸á€€á€­á€¯ á€•á€¼á€±á€¬á€á€²á€·á€á€šá€ºá‹\n",
      "\n",
      "Original: á€”á€±á€¬á€€á€ºá€”á€±á€·á€™á€¾á€¬ á€á€°á€á€­á€¯á€· á€•á€»á€±á€¬á€€á€ºá€á€½á€¬á€¸á€á€šá€ºá‹\n",
      "Generated: á€”á€±á€¬á€€á€ºá€”á€±á€·á€™á€¾á€¬ á€á€°á€á€­á€¯á€· á€•á€»á€±á€¬á€€á€ºá€á€½á€¬á€¸á€á€šá€ºá‹\n",
      "\n",
      "Original: Julius Hersheimmer á€á€Šá€º á€¡á€¬á€¸á€€á€…á€¬á€¸á€á€½á€„á€º á€‘á€°á€¸á€á€»á€½á€”á€ºá€á€°á€–á€¼á€…á€ºá€á€Šá€ºá‹\n",
      "Generated: Julius Hersheimmer á€á€Šá€º á€¡á€¬á€¸á€€á€…á€¬á€¸á€á€½á€„á€º á€‘á€°á€¸á€á€»á€½á€”á€ºá€á€°á€–á€¼á€…á€ºá€á€Šá€ºá‹\n",
      "\n",
      "Model: XLM-R\n",
      "Original: á€’á€«á€Ÿá€¬ á€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯á€á€…á€ºá€á€¯á€•á€«á‹ á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€‘á€¬á€á€…á€‰á€ºá€‘á€±á€¬á€„á€ºá€’á€á€ºá€á€»á€™á€¾á€á€ºá€á€„á€·á€ºá€á€œá€±á€¬ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€¡á€–á€½á€²á€·á€¡á€…á€Šá€ºá€¸á€–á€½á€²á€·á€…á€Šá€ºá€¸á€€á€¬ á€•á€¼á€¯á€•á€¼á€„á€ºá€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€›á€”á€º á€€á€¼á€­á€¯á€¸á€•á€™á€ºá€¸á€á€„á€·á€ºá€•á€«á€á€œá€¬á€¸á‹\n",
      "Generated: á€’á€«á€Ÿá€¬ á€›á€½á€±á€¸á€á€»á€šá€ºá€™á€¾á€¯á€á€…á€ºá€á€¯á€•á€«á‹ á€€á€»á€½á€”á€ºá€¯á€•á€ºá€á€­á€¯á€·á€á€Šá€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€‘á€¬á€á€…á€‰á€ºá€‘á€±á€¬á€„á€ºá€’á€á€ºá€á€»á€™á€¾á€á€ºá€á€„á€·á€ºá€á€œá€±á€¬ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º áá€„á€ºá€¸á€á€­á€¯á€·á€¡á€¬á€¸ á€¡á€–á€½á€²á€·á€¡á€…á€Šá€ºá€¸á€–á€½á€²á€·á€…á€Šá€ºá€¸á€€á€¬ á€•á€¼á€¯á€•á€¼á€„á€ºá€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€›á€”á€º á€€á€¼á€­á€¯á€¸á€•á€™á€ºá€¸á€á€„á€·á€ºá€•á€«á€á€œá€¬á€¸á‹\n",
      "\n",
      "Original: á€¡á€›á€±á€¬á€„á€ºá€¸á€€á€½á€„á€ºá€¸á€á€Šá€º á€¡á€œá€¯á€•á€ºá€á€™á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€”á€¹á€á€›á€¬á€šá€ºá€–á€¼á€…á€ºá€…á€±á€›á€”á€º á€’á€®á€‡á€­á€¯á€„á€ºá€¸á€‘á€¯á€á€ºá€‘á€¬á€¸á€á€Šá€ºá‹\n",
      "Generated: á€¡á€›á€±á€¬á€„á€ºá€¸á€€á€½á€„á€ºá€¸á€á€Šá€º á€¡á€œá€¯á€•á€ºá€á€™á€¬á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€”á€¹á€á€›á€¬á€šá€ºá€–á€¼á€…á€ºá€…á€±á€›á€”á€º á€’á€®á€‡á€­á€¯á€„á€ºá€¸á€‘á€¯á€á€ºá€‘á€¬á€¸á€á€Šá€ºá‹\n",
      "\n",
      "Original: á€¡á€‘á€°á€¸á€á€–á€¼á€„á€·á€º Tuppence á€€ á€šá€¬á€‰á€ºá€™á€±á€¬á€„á€ºá€¸á€€á€­á€¯ á€•á€¼á€±á€¬á€á€²á€·á€á€šá€ºá‹\n",
      "Generated: á€¡á€‘á€°á€¸á€á€–á€¼á€„á€·á€º Tuppence á€€ á€šá€¬á€‰á€ºá€™á€±á€¬á€„á€ºá€¸á€€á€­á€¯ á€•á€¼á€±á€¬á€á€²á€·á€á€šá€ºá‹\n",
      "\n",
      "Original: á€”á€±á€¬á€€á€ºá€”á€±á€·á€™á€¾á€¬ á€á€°á€á€­á€¯á€· á€•á€»á€±á€¬á€€á€ºá€á€½á€¬á€¸á€á€šá€ºá‹\n",
      "Generated: á€”á€±á€¬á€€á€ºá€”á€±á€·á€™á€¾á€¬ á€á€°á€á€­á€¯á€· á€•á€»á€±á€¬á€€á€ºá€á€½á€¬á€¸á€á€šá€ºá‹\n",
      "\n",
      "Original: Julius Hersheimmer á€á€Šá€º á€¡á€¬á€¸á€€á€…á€¬á€¸á€á€½á€„á€º á€‘á€°á€¸á€á€»á€½á€”á€ºá€á€°á€–á€¼á€…á€ºá€á€Šá€ºá‹\n",
      "Generated: Julius Hersheimmer á€á€Šá€º á€¡á€¬á€¸á€€á€…á€¬á€¸á€á€½á€„á€º á€‘á€°á€¸á€á€»á€½á€”á€ºá€á€°á€–á€¼á€…á€ºá€á€Šá€ºá‹\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 5 Burmese sentences\n",
    "multilingual_sample_texts = mBERT_XLMR_evaludation_results[\"burmese\"].sample(5).tolist()\n",
    "\n",
    "# Process all models in batch\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    # Get predictions for the entire batch at once\n",
    "    generated_texts = generate_masked_predictions_batch(multilingual_sample_texts, model_name)\n",
    "\n",
    "    # Print results\n",
    "    for original, generated in zip(multilingual_sample_texts, generated_texts):\n",
    "        print(f\"Original: {original}\")\n",
    "        print(f\"Generated: {generated}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Compare BLEU, ROUGE, and Perplexity scores between ```mBERT``` and ```XLM-R```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute BLEU score\n",
    "def compute_bleu_multilingual(reference, prediction):\n",
    "    return sentence_bleu([reference.split()], prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all models in batch\n",
    "lstm_bleu_batch_size = 32\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"Processing {model_name}...\")\n",
    "\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_generated\"] = [\n",
    "        pred for batch in tqdm(\n",
    "            [mBERT_XLMR_evaludation_results[\"burmese\"][i : i + lstm_bleu_batch_size] for i in range(0, len(mBERT_XLMR_evaludation_results), lstm_bleu_batch_size)],\n",
    "            desc=f\"Generating {model_name}\"\n",
    "        )\n",
    "        for pred in generate_masked_predictions_batch(batch, model_name)\n",
    "    ]\n",
    "\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_bleu\"] = [\n",
    "        compute_bleu_multilingual(row[\"english\"], row[f\"{model_name}_generated\"])\n",
    "        for _, row in tqdm(mBERT_XLMR_evaludation_results.iterrows(), total=len(mBERT_XLMR_evaludation_results), desc=f\"Computing BLEU {model_name}\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BLEU scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} BLEU Score: {mBERT_XLMR_evaludation_results[f'{model_name}_bleu'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bleu scores\n",
    "save_tmp_df(mBERT_XLMR_evaludation_results, \"mBERT_XLMR_evaludation_results_bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE Score\n",
    "multilingual_rouge_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "for model_name in multilingual_model_names:\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_rouge\"] = mBERT_XLMR_evaludation_results.progress_apply(\n",
    "        lambda row: multilingual_rouge_scorer.score(row[\"english\"], row[f\"{model_name}_generated\"])[\"rougeL\"].fmeasure, axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROUGE scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} ROUGE Score: {mBERT_XLMR_evaludation_results[f'{model_name}_rouge'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ROUGE scores\n",
    "save_tmp_df(mBERT_XLMR_evaludation_results, \"mBERT_XLMR_evaludation_results_rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute perplexity\n",
    "def compute_perplexity_multilingual_batch(texts, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name].to(device)\n",
    "\n",
    "    # Ensure all inputs are valid strings and replace NaN/None\n",
    "    valid_texts = [str(text) if isinstance(text, str) else \"\" for text in texts]\n",
    "\n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(valid_texts, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Run the model in batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = F.log_softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Compute Perplexity for each sentence in batch\n",
    "    perplexities = torch.exp(-log_likelihood.mean(dim=(1, 2))).tolist()\n",
    "\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_perplexity_batch_size = 32\n",
    "\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"Computing Perplexity for {model_name}...\")\n",
    "\n",
    "    # Process in batches\n",
    "    perplexity_scores = []\n",
    "    for batch in tqdm(\n",
    "        [mBERT_XLMR_evaludation_results[f\"{model_name}_generated\"][i : i + multilingual_perplexity_batch_size].dropna().tolist()\n",
    "         for i in range(0, len(mBERT_XLMR_evaludation_results), multilingual_perplexity_batch_size)\n",
    "        ],\n",
    "        desc=f\"Perplexity {model_name}\"\n",
    "    ):\n",
    "        perplexity_scores.extend(compute_perplexity_multilingual_batch(batch, model_name))\n",
    "\n",
    "    # Store perplexity scores in DataFrame\n",
    "    mBERT_XLMR_evaludation_results[f\"{model_name}_perplexity\"] = perplexity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Perplexity scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} BLEU Score: {mBERT_XLMR_evaludation_results[f'{model_name}_perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ROUGE scores\n",
    "save_tmp_df(mBERT_XLMR_evaludation_results, \"mBERT_XLMR_evaludation_results_perplexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_models_df(mBERT_XLMR_evaludation_results, \"mBERT_XLMR_evaludation_results\")\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Benchmarking and Analysis\n",
    "Compare the performance of LSTM, mBERT, and XLM-R using BLEU, ROUGE, and Perplexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
