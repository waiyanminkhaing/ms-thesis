{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence_transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from rouge_score import rouge_scorer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mac\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        print(\"GPU details: \", details)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# set GPU device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window / Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for window\n",
    "print(\"Tensorflow GPUs: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using PyTorch device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save models df\n",
    "def save_models_df(df, df_name):\n",
    "    df.to_csv(f\"models/{df_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load spt df\n",
    "def load_spt_df(df_name):\n",
    "    return pd.read_csv(f\"spt/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load models df\n",
    "def load_models_df(df_name):\n",
    "    return pd.read_csv(f\"models/{df_name}.csv\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Before training our RNN/LSTM model, we need to load, process, and prepare the dataset. This step ensures that our input data is structured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Tokenized Sentences \n",
    "Load BPE tokenized datasets, convert tokens into sequences, and apply padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "english_columns = [\n",
    "     \"english_tokens\"\n",
    "    ,\"english_back_translated_tokens\"\n",
    "]\n",
    "burmese_columns = [\n",
    "    \"burmese_tokens\"\n",
    "    ,\"burmese_translated_tokens\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and file paths\n",
    "datasets = {\n",
    "    \"normal\": [\n",
    "        \"tokenized_bpe_myxnli_normalized_1\", \n",
    "        \"tokenized_bpe_myxnli_normalized_2\", \n",
    "        \"tokenized_bpe_alt_combined_normalized\"\n",
    "    ],\n",
    "    \"nllb_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_1\", \n",
    "        \"tokenized_bpe_myxnli_nllb_back_translated_final_2\", \n",
    "        \"tokenized_bpe_alt_combined_nllb_back_translated_final\"\n",
    "    ],\n",
    "    \"seamless_m4t_back_translated\": [\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_1\",\n",
    "        \"tokenized_bpe_myxnli_seamless_m4t_back_translated_final_2\",\n",
    "        \"tokenized_bpe_alt_combined_seamless_m4t_back_translated_final\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "def rename_columns(df):\n",
    "    column_mapping = {\n",
    "        \"english_back_translated\": \"english\",\n",
    "        \"burmese_translated\": \"burmese\",\n",
    "        \"english_back_translated_tokens\": \"english_tokens\",\n",
    "        \"burmese_translated_tokens\": \"burmese_tokens\",\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Ensure only required columns exist\n",
    "    df = df[[\"english\", \"burmese\", \"english_tokens\", \"burmese_tokens\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process dataset\n",
    "def load_and_process_dataset(file_name):\n",
    "    df = load_spt_df(f\"{file_name}\")\n",
    "\n",
    "    # Rename columns\n",
    "    df = rename_columns(df)\n",
    "\n",
    "    for column in english_columns:\n",
    "        if column in df.columns:\n",
    "            df[\"english_seq\"] = df[column].apply(lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else [])\n",
    "\n",
    "    for column in burmese_columns:\n",
    "        if column in df.columns:\n",
    "            df[\"burmese_seq\"] = df[column].apply(lambda x: sp.EncodeAsIds(str(x)) if isinstance(x, str) else [])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "processed_datasets = {\n",
    "    key: [load_and_process_dataset(file) for file in file_list] for key, file_list in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "full_data = pd.concat(\n",
    "    processed_datasets[\"normal\"] + \n",
    "    processed_datasets[\"nllb_back_translated\"] + \n",
    "    processed_datasets[\"seamless_m4t_back_translated\"],\n",
    "    ignore_index=True  # Reset index to avoid duplicates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data to prevent order bias\n",
    "full_data = full_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1627576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>english_seq</th>\n",
       "      <th>burmese_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the palace is empty except for antiquities and...</td>\n",
       "      <td>á€”á€”á€ºá€¸á€á€±á€¬á€ºá€™á€¾á€¬ á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€”á€²á€· á€¡á€á€”á€ºá€¸á€œá€±á€¸á€á€”...</td>\n",
       "      <td>['â–the', 'â–palace', 'â–is', 'â–empty', 'â–except'...</td>\n",
       "      <td>['â–á€”á€”á€ºá€¸á€á€±á€¬á€º', 'á€™á€¾á€¬', 'â–á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸', 'á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these things are all thought of as classic fra...</td>\n",
       "      <td>á€¤á€¡á€›á€¬á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€•á€¼á€„á€ºá€á€…á€ºá€‚á€”á€¹á€‘á€á€„á€ºá€¡á€–á€¼á€…á€º á€šá€°á€†á€‘á€¬á€¸á€á€Šá€ºá‹</td>\n",
       "      <td>['â–these', 'â–things', 'â–are', 'â–all', 'â–though...</td>\n",
       "      <td>['â–á€¤á€¡á€›á€¬', 'á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯', 'â–á€•á€¼á€„á€ºá€á€…á€º', 'á€‚', 'á€”á€¹',...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal government's monetary budget proce...</td>\n",
       "      <td>á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯á€¡á€…á€­á€¯á€¸á€›á€›á€²á€· á€„á€½á€±á€€á€¼á€±á€¸á€¡á€á€¼á€±á€á€¶ á€˜á€á€ºá€‚á€»á€€á€ºá€œá€¯á€•á€º...</td>\n",
       "      <td>['â–the', 'â–federal', 'â–government', \"'\", 's', ...</td>\n",
       "      <td>['â–á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯', 'á€¡á€…á€­á€¯á€¸á€›á€›á€²á€·', 'â–á€„á€½á€±á€€á€¼á€±á€¸', 'á€¡á€á€¼...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1707, 30...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the house was huge.</td>\n",
       "      <td>á€¡á€­á€™á€ºá€€ á€€á€¼á€®á€¸á€™á€¬á€¸á€á€²á€·á€á€šá€ºá‹</td>\n",
       "      <td>['â–the', 'â–house', 'â–was', 'â–huge', '.']</td>\n",
       "      <td>['â–á€¡á€­á€™á€ºá€€', 'â–á€€á€¼á€®á€¸á€™á€¬á€¸', 'á€á€²á€·á€á€šá€ºá‹']</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you won't find a single spice shop on ibiza.</td>\n",
       "      <td>Ibiza á€™á€¾á€¬ á€Ÿá€„á€ºá€¸á€á€á€ºá€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€ºá€†á€­á€¯á€„á€º á€á€…á€ºá€á€¯á€™á€¾ á€™á€...</td>\n",
       "      <td>['â–you', 'â–won', \"'\", 't', 'â–find', 'â–a', 'â–si...</td>\n",
       "      <td>['â–Ibiza', 'â–á€™á€¾á€¬', 'â–á€Ÿá€„á€ºá€¸á€á€á€º', 'á€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€º'...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the palace is empty except for antiquities and...   \n",
       "1  these things are all thought of as classic fra...   \n",
       "2  the federal government's monetary budget proce...   \n",
       "3                                the house was huge.   \n",
       "4       you won't find a single spice shop on ibiza.   \n",
       "\n",
       "                                             burmese  \\\n",
       "0  á€”á€”á€ºá€¸á€á€±á€¬á€ºá€™á€¾á€¬ á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€”á€²á€· á€¡á€á€”á€ºá€¸á€œá€±á€¸á€á€”...   \n",
       "1      á€¤á€¡á€›á€¬á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€•á€¼á€„á€ºá€á€…á€ºá€‚á€”á€¹á€‘á€á€„á€ºá€¡á€–á€¼á€…á€º á€šá€°á€†á€‘á€¬á€¸á€á€Šá€ºá‹   \n",
       "2  á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯á€¡á€…á€­á€¯á€¸á€›á€›á€²á€· á€„á€½á€±á€€á€¼á€±á€¸á€¡á€á€¼á€±á€á€¶ á€˜á€á€ºá€‚á€»á€€á€ºá€œá€¯á€•á€º...   \n",
       "3                               á€¡á€­á€™á€ºá€€ á€€á€¼á€®á€¸á€™á€¬á€¸á€á€²á€·á€á€šá€ºá‹   \n",
       "4  Ibiza á€™á€¾á€¬ á€Ÿá€„á€ºá€¸á€á€á€ºá€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€ºá€†á€­á€¯á€„á€º á€á€…á€ºá€á€¯á€™á€¾ á€™á€...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['â–the', 'â–palace', 'â–is', 'â–empty', 'â–except'...   \n",
       "1  ['â–these', 'â–things', 'â–are', 'â–all', 'â–though...   \n",
       "2  ['â–the', 'â–federal', 'â–government', \"'\", 's', ...   \n",
       "3           ['â–the', 'â–house', 'â–was', 'â–huge', '.']   \n",
       "4  ['â–you', 'â–won', \"'\", 't', 'â–find', 'â–a', 'â–si...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['â–á€”á€”á€ºá€¸á€á€±á€¬á€º', 'á€™á€¾á€¬', 'â–á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸', 'á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½...   \n",
       "1  ['â–á€¤á€¡á€›á€¬', 'á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯', 'â–á€•á€¼á€„á€ºá€á€…á€º', 'á€‚', 'á€”á€¹',...   \n",
       "2  ['â–á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯', 'á€¡á€…á€­á€¯á€¸á€›á€›á€²á€·', 'â–á€„á€½á€±á€€á€¼á€±á€¸', 'á€¡á€á€¼...   \n",
       "3                  ['â–á€¡á€­á€™á€ºá€€', 'â–á€€á€¼á€®á€¸á€™á€¬á€¸', 'á€á€²á€·á€á€šá€ºá‹']   \n",
       "4  ['â–Ibiza', 'â–á€™á€¾á€¬', 'â–á€Ÿá€„á€ºá€¸á€á€á€º', 'á€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€º'...   \n",
       "\n",
       "                                         english_seq  \\\n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...   \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...   \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 1707, 30...   \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...   \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...   \n",
       "\n",
       "                                         burmese_seq  \n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...  \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...  \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...  \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...  \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(full_data)}\")\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Padding to Sequences\n",
    "Ensure that all sequences have the same length for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust based on dataset analysis\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences padded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>burmese</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>burmese_tokens</th>\n",
       "      <th>english_seq</th>\n",
       "      <th>burmese_seq</th>\n",
       "      <th>burmese_seq_padded</th>\n",
       "      <th>english_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the palace is empty except for antiquities and...</td>\n",
       "      <td>á€”á€”á€ºá€¸á€á€±á€¬á€ºá€™á€¾á€¬ á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€”á€²á€· á€¡á€á€”á€ºá€¸á€œá€±á€¸á€á€”...</td>\n",
       "      <td>['â–the', 'â–palace', 'â–is', 'â–empty', 'â–except'...</td>\n",
       "      <td>['â–á€”á€”á€ºá€¸á€á€±á€¬á€º', 'á€™á€¾á€¬', 'â–á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸', 'á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "      <td>[8777, 30887, 4879, 30887, 30883, 1519, 79, 30...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 5187, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these things are all thought of as classic fra...</td>\n",
       "      <td>á€¤á€¡á€›á€¬á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€•á€¼á€„á€ºá€á€…á€ºá€‚á€”á€¹á€‘á€á€„á€ºá€¡á€–á€¼á€…á€º á€šá€°á€†á€‘á€¬á€¸á€á€Šá€ºá‹</td>\n",
       "      <td>['â–these', 'â–things', 'â–are', 'â–all', 'â–though...</td>\n",
       "      <td>['â–á€¤á€¡á€›á€¬', 'á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯', 'â–á€•á€¼á€„á€ºá€á€…á€º', 'á€‚', 'á€”á€¹',...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "      <td>[8777, 30887, 15390, 30887, 30883, 1519, 2002,...</td>\n",
       "      <td>[8777, 30887, 857, 30887, 30883, 1519, 1298, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the federal government's monetary budget proce...</td>\n",
       "      <td>á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯á€¡á€…á€­á€¯á€¸á€›á€›á€²á€· á€„á€½á€±á€€á€¼á€±á€¸á€¡á€á€¼á€±á€á€¶ á€˜á€á€ºá€‚á€»á€€á€ºá€œá€¯á€•á€º...</td>\n",
       "      <td>['â–the', 'â–federal', 'â–government', \"'\", 's', ...</td>\n",
       "      <td>['â–á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯', 'á€¡á€…á€­á€¯á€¸á€›á€›á€²á€·', 'â–á€„á€½á€±á€€á€¼á€±á€¸', 'á€¡á€á€¼...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1707, 30...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "      <td>[8777, 30887, 2315, 30887, 30883, 1519, 19809,...</td>\n",
       "      <td>[30887, 30883, 1519, 1707, 30887, 30883, 1519,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the house was huge.</td>\n",
       "      <td>á€¡á€­á€™á€ºá€€ á€€á€¼á€®á€¸á€™á€¬á€¸á€á€²á€·á€á€šá€ºá‹</td>\n",
       "      <td>['â–the', 'â–house', 'â–was', 'â–huge', '.']</td>\n",
       "      <td>['â–á€¡á€­á€™á€ºá€€', 'â–á€€á€¼á€®á€¸á€™á€¬á€¸', 'á€á€²á€·á€á€šá€ºá‹']</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "      <td>[8777, 30887, 13319, 30887, 30883, 1519, 1809,...</td>\n",
       "      <td>[8777, 30887, 12, 30887, 30883, 1519, 1334, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you won't find a single spice shop on ibiza.</td>\n",
       "      <td>Ibiza á€™á€¾á€¬ á€Ÿá€„á€ºá€¸á€á€á€ºá€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€ºá€†á€­á€¯á€„á€º á€á€…á€ºá€á€¯á€™á€¾ á€™á€...</td>\n",
       "      <td>['â–you', 'â–won', \"'\", 't', 'â–find', 'â–a', 'â–si...</td>\n",
       "      <td>['â–Ibiza', 'â–á€™á€¾á€¬', 'â–á€Ÿá€„á€ºá€¸á€á€á€º', 'á€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€º'...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "      <td>[8777, 30887, 11090, 30887, 30883, 1519, 571, ...</td>\n",
       "      <td>[8777, 30887, 173, 30887, 30883, 1519, 1892, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  the palace is empty except for antiquities and...   \n",
       "1  these things are all thought of as classic fra...   \n",
       "2  the federal government's monetary budget proce...   \n",
       "3                                the house was huge.   \n",
       "4       you won't find a single spice shop on ibiza.   \n",
       "\n",
       "                                             burmese  \\\n",
       "0  á€”á€”á€ºá€¸á€á€±á€¬á€ºá€™á€¾á€¬ á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½á€±á€”á€²á€· á€¡á€á€”á€ºá€¸á€œá€±á€¸á€á€”...   \n",
       "1      á€¤á€¡á€›á€¬á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯ á€•á€¼á€„á€ºá€á€…á€ºá€‚á€”á€¹á€‘á€á€„á€ºá€¡á€–á€¼á€…á€º á€šá€°á€†á€‘á€¬á€¸á€á€Šá€ºá‹   \n",
       "2  á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯á€¡á€…á€­á€¯á€¸á€›á€›á€²á€· á€„á€½á€±á€€á€¼á€±á€¸á€¡á€á€¼á€±á€á€¶ á€˜á€á€ºá€‚á€»á€€á€ºá€œá€¯á€•á€º...   \n",
       "3                               á€¡á€­á€™á€ºá€€ á€€á€¼á€®á€¸á€™á€¬á€¸á€á€²á€·á€á€šá€ºá‹   \n",
       "4  Ibiza á€™á€¾á€¬ á€Ÿá€„á€ºá€¸á€á€á€ºá€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€ºá€†á€­á€¯á€„á€º á€á€…á€ºá€á€¯á€™á€¾ á€™á€...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  ['â–the', 'â–palace', 'â–is', 'â–empty', 'â–except'...   \n",
       "1  ['â–these', 'â–things', 'â–are', 'â–all', 'â–though...   \n",
       "2  ['â–the', 'â–federal', 'â–government', \"'\", 's', ...   \n",
       "3           ['â–the', 'â–house', 'â–was', 'â–huge', '.']   \n",
       "4  ['â–you', 'â–won', \"'\", 't', 'â–find', 'â–a', 'â–si...   \n",
       "\n",
       "                                      burmese_tokens  \\\n",
       "0  ['â–á€”á€”á€ºá€¸á€á€±á€¬á€º', 'á€™á€¾á€¬', 'â–á€›á€¾á€±á€¸á€Ÿá€±á€¬á€„á€ºá€¸', 'á€•á€…á€¹á€…á€Šá€ºá€¸á€á€½...   \n",
       "1  ['â–á€¤á€¡á€›á€¬', 'á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯', 'â–á€•á€¼á€„á€ºá€á€…á€º', 'á€‚', 'á€”á€¹',...   \n",
       "2  ['â–á€•á€¼á€Šá€ºá€‘á€±á€¬á€„á€ºá€…á€¯', 'á€¡á€…á€­á€¯á€¸á€›á€›á€²á€·', 'â–á€„á€½á€±á€€á€¼á€±á€¸', 'á€¡á€á€¼...   \n",
       "3                  ['â–á€¡á€­á€™á€ºá€€', 'â–á€€á€¼á€®á€¸á€™á€¬á€¸', 'á€á€²á€·á€á€šá€ºá‹']   \n",
       "4  ['â–Ibiza', 'â–á€™á€¾á€¬', 'â–á€Ÿá€„á€ºá€¸á€á€á€º', 'á€¡á€™á€½á€¾á€±á€¸á€¡á€€á€¼á€­á€¯á€„á€º'...   \n",
       "\n",
       "                                         english_seq  \\\n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...   \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...   \n",
       "2  [8777, 30887, 12, 30887, 30883, 1519, 1707, 30...   \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...   \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...   \n",
       "\n",
       "                                         burmese_seq  \\\n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...   \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...   \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...   \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...   \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...   \n",
       "\n",
       "                                  burmese_seq_padded  \\\n",
       "0  [8777, 30887, 4879, 30887, 30883, 1519, 79, 30...   \n",
       "1  [8777, 30887, 15390, 30887, 30883, 1519, 2002,...   \n",
       "2  [8777, 30887, 2315, 30887, 30883, 1519, 19809,...   \n",
       "3  [8777, 30887, 13319, 30887, 30883, 1519, 1809,...   \n",
       "4  [8777, 30887, 11090, 30887, 30883, 1519, 571, ...   \n",
       "\n",
       "                                  english_seq_padded  \n",
       "0  [8777, 30887, 12, 30887, 30883, 1519, 5187, 30...  \n",
       "1  [8777, 30887, 857, 30887, 30883, 1519, 1298, 3...  \n",
       "2  [30887, 30883, 1519, 1707, 30887, 30883, 1519,...  \n",
       "3  [8777, 30887, 12, 30887, 30883, 1519, 1334, 30...  \n",
       "4  [8777, 30887, 173, 30887, 30883, 1519, 1892, 3...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply padding\n",
    "full_data[\"burmese_seq_padded\"] = pad_sequences(full_data[\"burmese_seq\"], maxlen=max_seq_length, padding=\"post\").tolist()\n",
    "full_data[\"english_seq_padded\"] = pad_sequences(full_data[\"english_seq\"], maxlen=max_seq_length, padding=\"post\").tolist()\n",
    "\n",
    "print(\"Sequences padded successfully!\")\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed data\n",
    "save_models_df(full_data, \"processed_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing RNN/LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SentencePiece BPE tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spt/spt_bpe.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Model\n",
    "Use a Bidirectional LSTM encoder-decoder with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lstm_embedding_dim = 256\n",
    "lstm_hidden_dim = 512\n",
    "lstm_vocab_size = sp.GetPieceSize()  # Get vocabulary size from SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 12:40:46.000879: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-01-30 12:40:46.000945: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-01-30 12:40:46.000960: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2025-01-30 12:40:46.000996: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-30 12:40:46.001014: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "with tf.device('/GPU:0'):  # Explicitly assign to GPU if available\n",
    "    lstm_model = Sequential([\n",
    "        Embedding(input_dim=lstm_vocab_size, output_dim=lstm_embedding_dim, mask_zero=True),\n",
    "        Bidirectional(LSTM(lstm_hidden_dim, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        LSTM(lstm_hidden_dim, return_sequences=False, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(lstm_vocab_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display Model Summary\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Train the model using full dataset (Normal + Back-Translated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed data\n",
    "lstm_processed_data = load_models_df(\"processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = np.array(lstm_processed_data[\"burmese_seq_padded\"].tolist())\n",
    "y_train_lstm = np.array(lstm_processed_data[\"english_seq_padded\"].tolist())\n",
    "\n",
    "# Train on GPU\n",
    "with tf.device('/GPU:0'):  \n",
    "    lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model with BLEU Score\n",
    "Compute BLEU Score for translation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode tokenized text back to sentences\n",
    "def decode_sentence_lstm(tokenized_seq):\n",
    "    return sp.DecodeIds([int(token) for token in tokenized_seq if token > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions\n",
    "lstm_sample_inputs = X_train_lstm[:5]\n",
    "lstm_sample_outputs = lstm_model.predict(lstm_sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions back to text\n",
    "lstm_generated_sentences = [decode_sentence_lstm(seq) for seq in lstm_sample_outputs]\n",
    "lstm_reference_sentences = [decode_sentence_lstm(seq) for seq in y_train_lstm[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU Score\n",
    "lstm_bleu_scores = [sentence_bleu([ref.split()], gen.split()) for ref, gen in zip(lstm_reference_sentences, lstm_generated_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for i in range(5):\n",
    "    print(f\"Reference: {lstm_reference_sentences[i]}\")\n",
    "    print(f\"Generated: {lstm_generated_sentences[i]}\")\n",
    "    print(f\"BLEU Score: {lstm_bleu_scores[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Export Model\n",
    "Save trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save(\"models/bpe_lstm_baseline_model.h5\")\n",
    "sp.Save(\"models/bpe_model_trained.model\")\n",
    "\n",
    "print(\"Model and tokenizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing Multilingual Transformer Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load And Save Pre-Trained Models\n",
    "Load ```mBERT``` and ```XLM-R``` for Masked Language Modeling (MLM).\n",
    "MLM helps predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model names\n",
    "multilingual_model_names = {\n",
    "    \"mBERT\": \"bert-base-multilingual-cased\",\n",
    "    \"XLM-R\": \"xlm-roberta-base\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers & models for both mBERT and XLM-R\n",
    "multilingual_tokenizers = {name: AutoTokenizer.from_pretrained(model) for name, model in multilingual_model_names.items()}\n",
    "multilingual_models = {name: AutoModelForMaskedLM.from_pretrained(model).to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for name, model in multilingual_model_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models\n",
    "for model_name in multilingual_model_names:\n",
    "    multilingual_models[model_name].save_pretrained(f\"models/{model_name}\")\n",
    "    multilingual_tokenizers[model_name].save_pretrained(f\"models/{model_name}\")\n",
    "    print(f\"{model_name} saved at models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed dataset\n",
    "multilingual_processed_data = load_models_df(\"processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only required columns\n",
    "multilingual_processed_data = multilingual_processed_data[[\"english\", \"burmese\", \"english_tokens\", \"burmese_tokens\"]]\n",
    "display(multilingual_processed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token sequences to list format\n",
    "multilingual_processed_data[\"burmese_tokens\"] = multilingual_processed_data[\"burmese_tokens\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "display(multilingual_processed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Models\n",
    "Load mBERT & XLM-R from disk without re-downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models and tokenizers\n",
    "multilingual_models = {name: AutoModelForMaskedLM.from_pretrained(f\"models/${name}\") for name in multilingual_model_names}\n",
    "multilingual_tokenizers = {name: AutoTokenizer.from_pretrained(f\"models/${name}\") for name in multilingual_model_names}\n",
    "\n",
    "print(\"Saved models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference Without Fine-Tuning\n",
    "Pass Burmese text through ```mBERT``` & ```XLM-R``` using Masked Language Modeling (MLM). mBERT/XLM-R predict missing words in Burmese sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate masked predictions\n",
    "def generate_masked_predictions(text, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Mask a random token in the sequence\n",
    "    mask_idx = torch.randint(1, inputs[\"input_ids\"].shape[1] - 1, (1,))\n",
    "    inputs[\"input_ids\"][0, mask_idx] = tokenizer.mask_token_id  # Replace one token with [MASK]\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get highest probability prediction for the masked token\n",
    "    predicted_token_id = torch.argmax(outputs.logits[0, mask_idx], dim=-1).item()\n",
    "    predicted_token = tokenizer.decode([predicted_token_id])\n",
    "\n",
    "    return text.replace(tokenizer.mask_token, predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample Burmese sentences\n",
    "sample_texts = multilingual_processed_data[\"burmese\"].sample(5).tolist()\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"ğŸ”¹ Model: {model_name}\")\n",
    "    for text in sample_texts:\n",
    "        print(f\"Original: {text}\")\n",
    "        print(f\"Generated: {generate_masked_predictions(text, model_name)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Compare BLEU, ROUGE, and Perplexity scores between ```mBERT``` and ```XLM-R```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute BLEU score\n",
    "def compute_bleu(reference, prediction):\n",
    "    return sentence_bleu([reference.split()], prediction.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on dataset\n",
    "for model_name in multilingual_model_names:\n",
    "    multilingual_processed_data[f\"{model_name}_generated\"] = multilingual_processed_data[\"burmese\"].apply(lambda x: generate_masked_predictions(x, model_name))\n",
    "    multilingual_processed_data[f\"{model_name}_bleu\"] = multilingual_processed_data.apply(lambda row: compute_bleu(row[\"english\"], row[f\"{model_name}_generated\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BLEU scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} BLEU Score: {multilingual_processed_data[f'{model_name}_bleu'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ROUGE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE Score\n",
    "multilingual_rouge_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "for model_name in multilingual_model_names:\n",
    "    multilingual_processed_data[f\"{model_name}_rouge\"] = multilingual_processed_data.apply(lambda row: multilingual_rouge_scorer.score(row[\"english\"], row[f\"{model_name}_generated\"])[\"rougeL\"].fmeasure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ROUGE scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} ROUGE Score: {multilingual_processed_data[f'{model_name}_rouge'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Perplexity Score\n",
    "Lower perplexity = Better fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute perplexity\n",
    "def compute_perplexity(text, model_name):\n",
    "    tokenizer = multilingual_tokenizers[model_name]\n",
    "    model = multilingual_models[model_name]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = F.log_softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Compute Perplexity\n",
    "    perplexity = torch.exp(-log_likelihood.mean()).item()\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity for both models\n",
    "for model_name in multilingual_model_names:\n",
    "    multilingual_processed_data[f\"{model_name}_perplexity\"] = multilingual_processed_data[f\"{model_name}_generated\"].apply(lambda x: compute_perplexity(x, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Perplexity scores\n",
    "for model_name in multilingual_model_names:\n",
    "    print(f\"{model_name} Perplexity Score: {multilingual_processed_data[f'{model_name}_perplexity'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "save_models_df(multilingual_processed_data, \"mBERT_XLMR_results\")\n",
    "print(\"Results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
