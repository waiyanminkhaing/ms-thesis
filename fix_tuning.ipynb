{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65efe3b-27ae-42cf-a711-56c6e273ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.45.2 sentence-transformers==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffff0754-7db6-4837-aab3-f95be80017c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 05:41:58.067615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-19 05:41:58.091754: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-19 05:41:58.091785: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-19 05:41:58.107221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-19 05:41:58.941033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Transformers is only compatible with Keras 2, but you have explicitly set `TF_USE_LEGACY_KERAS` to `0`. This may result in unexpected behaviour or errors if Keras 3 objects are passed to Transformers models.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, TrainingArguments, EarlyStoppingCallback, Trainer\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from utils.gpu import get_device\n",
    "from utils.common import (\n",
    "    generate_masked_predictions_hf_batch, generate_mt5_predictions,\n",
    "    compute_metrics_hf,\n",
    "    convert_to_mean_scores_df,\n",
    "    get_fine_tuned_model, get_embedded_fine_tuned_model,\n",
    "    compute_multilingual_masked_perplexity_single, compute_multilingual_mt5_perplexity_single,\n",
    "    extract_extended_metrics_from_logs,\n",
    ")\n",
    "from utils.dataframe import (\n",
    "    load_gen_df, save_tmp_df, load_tmp_df, load_models_df,\n",
    "    save_model_variants_df, load_model_variants_df,\n",
    "    save_model_variants_hf, load_model_variants_hf,\n",
    "    save_model_variants_gen_df, load_model_variants_gen_df,\n",
    "    convert_to_hf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9af449-ff25-4bca-abf4-a7c5f2b4d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Using PyTorch device: cuda\n",
      "GPU Name: NVIDIA A10G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 05:42:00.879213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-19 05:42:00.917558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-19 05:42:00.919528: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# gpu device \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b37c8eb-2102-451f-b5c7-4d311ff55657",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\", use_fast=False, legacy=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425f77c9-092f-43fa-804c-53df4c5bc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Prefix Tuning Parameters (THIS IS WHERE THEY ARE CREATED)\n",
    "prefix_length = 10\n",
    "num_prefixes = model.config.num_layers * 2\n",
    "prefix_projection_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31300953-5a12-42e7-b21d-396428667a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prefix embeddings:\n",
    "prefixes = torch.nn.Embedding(num_prefixes, prefix_length * prefix_projection_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f0b188-70bd-416b-84fa-5a88b97b75fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of prefixes: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Device of prefixes:\", prefixes.weight.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238bad69-abbf-4763-b2f0-5a44f95be081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prefix projection layer (optional, but often recommended):\n",
    "prefix_projection = torch.nn.Sequential(\n",
    "    torch.nn.Linear(prefix_length * prefix_projection_dim, model.config.d_model),\n",
    "    torch.nn.Tanh()  # Or another activation function\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ec4ea1-33d0-4d17-b02c-0f3f26e79d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(model, model_name):\n",
    "    \"\"\"\n",
    "    Applies LoRA for efficient fine-tuning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select correct LoRA target layers\n",
    "    if \"t5\" in model_name.lower():\n",
    "        target_modules = [\"q\", \"v\"]  # LoRA for T5/mT5\n",
    "    else:\n",
    "        target_modules = [\"query\", \"value\"]  # LoRA for BERT\n",
    "\n",
    "    # Define LoRA Configuration\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,                    # Rank of LoRA matrices\n",
    "        lora_alpha=16,          # Scaling factor\n",
    "        target_modules=target_modules,  \n",
    "        lora_dropout=0.1,       # Prevents overfitting\n",
    "    )\n",
    "\n",
    "    # Apply LoRA\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Move model to GPU\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"LoRA applied to {model_name} (Target Modules: {target_modules})\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803c7e62-cdcf-4642-bf51-61a5cfd83a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA applied to mT5-small (Target Modules: ['q', 'v'])\n"
     ]
    }
   ],
   "source": [
    "model = apply_lora(model, \"mT5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f5f2d1-2fda-4210-b98b-2dde1ab89af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = f\"Prefix_mT5_UNIGRAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb347f8-b95f-4330-be40-bf682ab3db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Define Training Arguments\n",
    "train_args = {\n",
    "    \"warmup_steps\": 500,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_total_limit\": 2,\n",
    "    \"fp16\": False,\n",
    "    \"bf16\": True,  # Mixed precision training\n",
    "    \"eval_strategy\": \"epoch\",\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"loss\",\n",
    "    \"greater_is_better\": False,\n",
    "    \"logging_steps\": 1000,\n",
    "    \"optim\": \"adamw_torch_fused\",\n",
    "    \"auto_find_batch_size\": True,\n",
    "    \"disable_tqdm\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6991263-8779-43bb-b5a8-064f5fa5490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Define TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    **train_args,\n",
    "    output_dir=f\"model-variants/results/{trained_model_name}\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=f\"model-variants/logs/{trained_model_name}\",\n",
    "    label_names=[\"labels\", \"input_ids\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed8b7c9-b719-4cf9-b425-dd6f4ce78bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrefixTuningTrainer(Trainer):\n",
    "    def __init__(self, *args, prefixes, prefix_projection, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        device = self.model.device\n",
    "        self.prefixes = prefixes.to(device)  # Ensure prefix embeddings are on GPU\n",
    "        self.prefix_projection = prefix_projection.to(device)  # Ensure prefix projection is on GPU\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Compute loss for prefix tuning.\n",
    "        \"\"\"\n",
    "        device = model.device  # Ensure all tensors are on the same device\n",
    "\n",
    "        # Move inputs to GPU\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        decoder_input_ids = inputs[\"labels\"].to(device)\n",
    "\n",
    "        # Fix padding issue (-100 should be replaced with decoder_start_token_id)\n",
    "        decoder_input_ids = decoder_input_ids.masked_fill(\n",
    "            decoder_input_ids == -100, model.config.decoder_start_token_id\n",
    "        )\n",
    "\n",
    "        # Ensure prefix tensor is on GPU\n",
    "        num_prefixes = self.prefixes.num_embeddings\n",
    "        prefix_ids = torch.arange(num_prefixes, device=device)\n",
    "        expanded_prefixes = self.prefixes(prefix_ids).unsqueeze(0).expand(input_ids.shape[0], -1, -1)\n",
    "\n",
    "        # Project prefix embeddings to model hidden dimension\n",
    "        projected_prefixes = self.prefix_projection(expanded_prefixes)\n",
    "        assert projected_prefixes.shape[-1] == model.config.d_model, \"Prefix projection mismatch!\"\n",
    "\n",
    "        # Convert token IDs to embeddings\n",
    "        inputs_embeds = model.encoder.embed_tokens(input_ids).to(device)\n",
    "        decoder_inputs_embeds = model.decoder.embed_tokens(decoder_input_ids).to(device)\n",
    "\n",
    "        # Concatenate prefix embeddings with inputs\n",
    "        inputs_embeds = torch.cat([projected_prefixes, inputs_embeds], dim=1)\n",
    "\n",
    "        # Update attention mask\n",
    "        new_seq_length = inputs_embeds.shape[1]\n",
    "        updated_attention_mask = torch.ones((attention_mask.shape[0], new_seq_length), device=device)\n",
    "        updated_attention_mask[:, projected_prefixes.shape[1]:] = attention_mask\n",
    "\n",
    "        # Forward pass with correct decoder embeddings\n",
    "        outputs = model(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=updated_attention_mask,\n",
    "            decoder_inputs_embeds=decoder_inputs_embeds,  # ✅ Use embeddings instead of decoder_input_ids\n",
    "            labels=decoder_input_ids  # ✅ Ensure loss is computed\n",
    "        )\n",
    "\n",
    "        # Extract loss\n",
    "        loss = outputs.loss if hasattr(outputs, \"loss\") else outputs[\"loss\"]\n",
    "\n",
    "        if loss is None:\n",
    "            raise ValueError(\"Model did not return a loss. Ensure labels are provided.\")\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dfd03dc-b330-49e8-a711-68b1a8439170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_data = load_model_variants_hf(f\"mt5_unigram_train\")\n",
    "val_data = load_model_variants_hf(f\"mt5_unigram_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc1e7e9-7ee5-40c9-b4b2-cc2d6aac259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug, remove comment\n",
    "#train_data = train_data.select(range(100))\n",
    "#val_data = val_data.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55e38f6-e0bd-456c-9b88-304f7b1db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Initialize PrefixTuningTrainer\n",
    "trainer = PrefixTuningTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    prefixes=prefixes,\n",
    "    prefix_projection=prefix_projection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a15ba-cec8-46a3-8f56-f93ae02b70db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112756' max='900501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112756/900501 9:46:35 < 68:18:10, 3.20 it/s, Epoch 0.38/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654749f-6684-43f3-9c8c-9987aa320b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model and tokenizer\n",
    "save_path = f\"model-variants/models/{trained_model_name}\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Model `mT5` fine-tuned and saved at `{save_path}`.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
