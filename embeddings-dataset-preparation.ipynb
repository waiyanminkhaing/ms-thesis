{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.dataframe import (\n",
    "    save_model_variants_chunk_hf,\n",
    "    load_model_variants_hf, save_model_variants_hf\n",
    ")\n",
    "from IPython.display import display\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from laserembeddings import Laser\n",
    "from utils.gpu import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# gpu device \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Enhance Burmese Contextual Representations\n",
    "- Use LASER, mUSE, and FastText for cross-lingual and morphology-aware training.\n",
    "- Fine-tune mBERT, XLM-R on Burmese dataset after adding contextual embeddings.\n",
    "- Train models again using combined embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk size\n",
    "embedded_train_chunk_sizes = {\n",
    "    \"mbert\": 20,\n",
    "    \"xlm-r\": 20,\n",
    "}\n",
    "embedded_test_chunk_sizes = {\n",
    "    \"mbert\": 5,\n",
    "    \"xlm-r\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splti train data\n",
    "# for model_name in [\"mbert\", \"xlm-r\"]:\n",
    "#     for spt_name in [\"bpe\", \"unigram\"]:\n",
    "#         name = f\"{model_name}_{spt_name}_train\"\n",
    "#         train_dataset = load_model_variants_hf(name)\n",
    "\n",
    "#         # split and save\n",
    "#         save_model_variants_hf(train_dataset, f\"embedded_{name}\", embedded_train_chunk_sizes[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splti test data\n",
    "# for model_name in [\"mbert\", \"xlm-r\"]:\n",
    "#     for spt_name in [\"bpe\", \"unigram\"]:\n",
    "#         name = f\"{model_name}_{spt_name}_test\"\n",
    "#         train_dataset = load_model_variants_hf(name)\n",
    "\n",
    "#         # split and save\n",
    "#         save_model_variants_hf(train_dataset, f\"embedded_{name}\", embedded_test_chunk_sizes[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASER Embeddings\n",
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 16:39:18.138296: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-02-25 16:39:18.138329: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-02-25 16:39:18.138334: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740469158.138354 14332168 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1740469158.138375 14332168 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-02-25 16:39:20.137072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# mUSE (Multilingual Universal Sentence Encoder)\n",
    "muse = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText for Morphology-Aware Training\n",
    "fasttext.util.download_model('my', if_exists='ignore')  # Download Burmese FastText model\n",
    "fasttext_model = fasttext.load_model('cc.my.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize projection layer (1836 → 768) in bf16\n",
    "projection_layer = nn.Linear(1836, 768).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(batch):\n",
    "    \"\"\"\n",
    "    Generates contextual embeddings using mUSE (TensorFlow), LASER, and FastText.\n",
    "    Uses Hugging Face Datasets to process batches efficiently.\n",
    "    Logs errors and stops execution on failure.\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = batch[\"target\"]\n",
    "    sentences = [str(text) if text is not None else \"\" for text in sentences]\n",
    "\n",
    "    # Ensure all sentences are valid strings\n",
    "    sentences = [s.replace(\"\\n\", \" \").strip() if s else \"\" for s in sentences]\n",
    "\n",
    "    # Generate mUSE embeddings (GPU-accelerated)\n",
    "    batch_tensor = tf.convert_to_tensor(sentences)\n",
    "    embeddings_muse = muse(batch_tensor).numpy()  # Shape: (batch_size, 512)\n",
    "\n",
    "    # Generate FastText embeddings\n",
    "    embeddings_fasttext = np.array([\n",
    "        fasttext_model.get_sentence_vector(sentence) for sentence in sentences\n",
    "    ])\n",
    "\n",
    "    # Generate LASER embeddings\n",
    "    embeddings_laser = laser.embed_sentences(sentences, lang=\"my\")\n",
    "\n",
    "    # Stack embeddings\n",
    "    combined_embeddings = np.hstack([\n",
    "        embeddings_muse,\n",
    "        embeddings_laser,\n",
    "        embeddings_fasttext\n",
    "    ])\n",
    "\n",
    "    # Convert to tensor & bf16\n",
    "    tensor_embeddings = torch.tensor(combined_embeddings, dtype=torch.bfloat16)\n",
    "\n",
    "    # Apply projection (1836 → 768)\n",
    "    projected_embeddings = projection_layer(tensor_embeddings).detach().tolist()\n",
    "\n",
    "    return {\"contextual_embeddings\": projected_embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and spt\n",
    "model_name = \"mbert\"\n",
    "spt_name = \"unigram\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk num\n",
    "chunk_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train path\n",
    "chunk_dataset_path = f\"embedded_{model_name}_{spt_name}_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-variants/data/embedded_mbert_unigram_train_hf_dataset/chunk_3\n",
      "Chunk Dataset Length: 65103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you can find the center of blackpool by follow...</td>\n",
       "      <td>Blackpool ရဲ့ ဗဟိုကို အမှတ်အသားတွေကို လိုက်ပြီ...</td>\n",
       "      <td>[101, 100, 100, 100, 100, 100, 100, 100, 10514...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 100, 10514, 30668, 100, 100, 39194, 100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we must only hope that our kashmir can be reso...</td>\n",
       "      <td>ကျွန်တော်တို့ရဲ့ ကက်ရှ်မီးယားကို ငြိမ်းချမ်းစွ...</td>\n",
       "      <td>[101, 100, 100, 100, 100, 100, 100, 100, 100, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[101, 100, 1518, 89114, 100, 39194, 100, 100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>each time, he sent photos to his friends and a...</td>\n",
       "      <td>အကြိမ်တိုင်း သူ့သူငယ်ချင်းတွေကို ဓာတ်ပုံတွေပို...</td>\n",
       "      <td>[101, 100, 100, 117, 100, 100, 100, 100, 100, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 100, 1507, 47341, 100, 1507, 111505, 241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there were no castes.</td>\n",
       "      <td>ဇာတ်မရှိခဲ့ပါ။</td>\n",
       "      <td>[101, 100, 100, 100, 100, 10196, 119, 102, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 100, 1516, 57586, 111470, 89114, 111489,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>but the oil is gone.</td>\n",
       "      <td>ဒါပေမဲ့ ဆီအသားအိတ်က ပျောက်နေတယ်။</td>\n",
       "      <td>[101, 100, 100, 100, 100, 100, 119, 102, 0, 0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[101, 100, 100, 1524, 69046, 1524, 53474, 2814...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  you can find the center of blackpool by follow...   \n",
       "1  we must only hope that our kashmir can be reso...   \n",
       "2  each time, he sent photos to his friends and a...   \n",
       "3                              there were no castes.   \n",
       "4                               but the oil is gone.   \n",
       "\n",
       "                                              target  \\\n",
       "0  Blackpool ရဲ့ ဗဟိုကို အမှတ်အသားတွေကို လိုက်ပြီ...   \n",
       "1  ကျွန်တော်တို့ရဲ့ ကက်ရှ်မီးယားကို ငြိမ်းချမ်းစွ...   \n",
       "2  အကြိမ်တိုင်း သူ့သူငယ်ချင်းတွေကို ဓာတ်ပုံတွေပို...   \n",
       "3                                     ဇာတ်မရှိခဲ့ပါ။   \n",
       "4                   ဒါပေမဲ့ ဆီအသားအိတ်က ပျောက်နေတယ်။   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 100, 100, 100, 100, 100, 100, 100, 10514...   \n",
       "1  [101, 100, 100, 100, 100, 100, 100, 100, 100, ...   \n",
       "2  [101, 100, 100, 117, 100, 100, 100, 100, 100, ...   \n",
       "3  [101, 100, 100, 100, 100, 10196, 119, 102, 0, ...   \n",
       "4  [101, 100, 100, 100, 100, 100, 119, 102, 0, 0,...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [101, 100, 10514, 30668, 100, 100, 39194, 100,...  \n",
       "1  [101, 100, 1518, 89114, 100, 39194, 100, 100, ...  \n",
       "2  [101, 100, 1507, 47341, 100, 1507, 111505, 241...  \n",
       "3  [101, 100, 1516, 57586, 111470, 89114, 111489,...  \n",
       "4  [101, 100, 100, 1524, 69046, 1524, 53474, 2814...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load chunk dataset\n",
    "chunk_dataset = load_model_variants_hf(chunk_dataset_path, chunk_num=chunk_num)\n",
    "print(f\"Chunk Dataset Length: {len(chunk_dataset)}\")\n",
    "display(chunk_dataset.to_pandas().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_embeddings at 0x39037a3b0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "WARNING:datasets.fingerprint:Parameter 'function'=<function generate_embeddings at 0x39037a3b0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69578078d57441bf9c64e71ed685e247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate embeddings\n",
    "chunk_dataset = chunk_dataset.map(generate_embeddings, batched=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(chunk_dataset.to_pandas().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save chunk dataset\n",
    "save_model_variants_chunk_hf(chunk_dataset, chunk_dataset_path, chunk_num=chunk_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_generated_list = []\n",
    "# for i in range(20):\n",
    "#     dataset = load_model_variants_hf(chunk_dataset_path, chunk_num=i)\n",
    "\n",
    "#     if \"contextual_embeddings\" not in dataset.to_pandas().columns:\n",
    "#         not_generated_list.append(i)\n",
    "\n",
    "# print(not_generated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis-tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
