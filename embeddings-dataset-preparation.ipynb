{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.dataframe import (\n",
    "    convert_to_hf,\n",
    "    load_model_variants_df,\n",
    "    save_model_variants_hf\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    ")\n",
    "from IPython.display import display\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from laserembeddings import Laser\n",
    "from utils.gpu import get_device\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# gpu device \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Enhance Burmese Contextual Representations\n",
    "- Use LASER, mUSE, and FastText for cross-lingual and morphology-aware training.\n",
    "- Fine-tune mBERT, XLM-R on Burmese dataset after adding contextual embeddings.\n",
    "- Train models again using combined embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get fine tuned tokenizer\n",
    "def get_fine_tuned_tokenizer(model_name, spt_name):\n",
    "    # Load LoRA Weights\n",
    "    lora_checkpoint_path = f\"model-variants/models/{model_name}_{spt_name.upper()}\"\n",
    "\n",
    "    # Load Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(lora_checkpoint_path)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASER Embeddings\n",
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 18:31:54.010274: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-02-19 18:31:54.010304: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2025-02-19 18:31:54.010308: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739957514.010328 1266786 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1739957514.010353 1266786 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-02-19 18:31:56.132603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# mUSE (Multilingual Universal Sentence Encoder)\n",
    "muse = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText for Morphology-Aware Training\n",
    "fasttext.util.download_model('my', if_exists='ignore')  # Download Burmese FastText model\n",
    "fasttext_model = fasttext.load_model('cc.my.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = load_model_variants_df(\"combined\")\n",
    "\n",
    "# split into train and test\n",
    "train_df = dataset.sample(frac=0.8, random_state=42)\n",
    "test_df = dataset.drop(train_df.index)\n",
    "\n",
    "# conert to hugging face dataset\n",
    "train_dataset = convert_to_hf(train_df)\n",
    "test_dataset = convert_to_hf(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences from DataFrame\n",
    "all_train_sentences = train_df[\"source\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "all_train_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   2%|‚ñè         | 80/5087 [01:33<1:41:24,  1.22s/it]"
     ]
    }
   ],
   "source": [
    "# generate embeddings\n",
    "for i in tqdm(range(0, len(all_train_sentences), batch_size), desc=\"Processing batches\"):\n",
    "    batch = all_train_sentences[i:i + batch_size]\n",
    "\n",
    "    # Generate embeddings on GPU\n",
    "    batch_tensor = tf.convert_to_tensor(batch)  # Convert to TensorFlow tensor\n",
    "    embeddings_muse = muse(batch_tensor).numpy()  # GPU-accelerated mUSE embeddings\n",
    "\n",
    "    # Generate FastText embeddings\n",
    "    embeddings_fasttext = np.array([\n",
    "        fasttext_model.get_sentence_vector(sentence.replace(\"\\n\", \" \").strip())  # Remove newlines\n",
    "        for sentence in batch\n",
    "    ])\n",
    "\n",
    "    # Generate LASER embeddings\n",
    "    embeddings_laser = laser.embed_sentences(batch, lang=\"my\")\n",
    "\n",
    "    # Stack all embeddings\n",
    "    combined_embeddings = np.hstack([embeddings_laser, embeddings_muse, embeddings_fasttext])\n",
    "    all_train_embeddings.append(combined_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "all_train_embeddings = np.concatenate(all_train_embeddings, axis=0)\n",
    "print(f\"Finished computing embeddings! Shape: {all_train_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying PCA for dimensionality reduction...\")\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(all_train_embeddings)  # Fit PCA on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training embeddings\n",
    "all_train_embeddings_pca = pca.transform(all_train_embeddings)\n",
    "print(f\"PCA applied! Reduced shape: {all_train_embeddings_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving embeddings and sentences to HDF5 format...\")\n",
    "\n",
    "with h5py.File(\"model-variants/data/contextual_train_embeddings.h5\", \"w\") as hf:\n",
    "    hf.create_dataset(\"embeddings\", data=all_train_embeddings_pca)\n",
    "    hf.create_dataset(\"sentences\", data=np.array(all_train_sentences, dtype=h5py.string_dtype(encoding=\"utf-8\")))\n",
    "\n",
    "print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HDF5 file\n",
    "with h5py.File(\"model-variants/data/contextual_train_embeddings.h5\", \"r\") as hf:\n",
    "    all_train_embeddings_pca = np.array(hf[\"embeddings\"])  # Load PCA-transformed embeddings\n",
    "    all_train_sentences = [s.decode(\"utf-8\") for s in hf[\"sentences\"]]  # Decode stored UTF-8 sentences\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging Output\n",
    "print(f\"‚úÖ Loaded PCA Embeddings Shape: {all_train_embeddings_pca.shape}\")  # Should be (num_samples, 300)\n",
    "print(f\"‚úÖ Loaded Sentences: {len(all_train_sentences)} samples\")  # Should match the number of embeddings\n",
    "print(f\"üîç Example Sentence: {all_train_sentences[0]}\")\n",
    "print(f\"üîç Example Embedding (first 5 values): {all_train_embeddings_pca[0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_contextual_embeddings(sentences):\n",
    "    \"\"\"Generates contextual embeddings using LASER, FastText, and mUSE.\"\"\"\n",
    "    sentences = [sentence.replace(\"\\n\", \" \").strip() for sentence in sentences]\n",
    "\n",
    "    # Generate embeddings on GPU\n",
    "    batch_tensor = tf.convert_to_tensor(sentences)\n",
    "    embeddings_muse = muse(batch_tensor).numpy()  # GPU-accelerated mUSE embeddings\n",
    "\n",
    "    embeddings_fasttext = np.array([\n",
    "        fasttext_model.get_sentence_vector(sentence) for sentence in sentences\n",
    "    ])  # FastText embeddings\n",
    "\n",
    "    embeddings_laser = laser.embed_sentences(sentences, lang=\"my\")  # LASER embeddings\n",
    "\n",
    "    # Apply PCA transformation\n",
    "    combined_embeddings = np.hstack([embeddings_laser, embeddings_muse, embeddings_fasttext])\n",
    "    contextual_embeddings = pca.transform(combined_embeddings)\n",
    "\n",
    "    return contextual_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def tokenize_with_contextual_embeddings(examples, tokenizer):\n",
    "    \"\"\"Tokenizes input sentences while integrating contextual embeddings.\"\"\"\n",
    "    sentences = examples[\"source\"]\n",
    "\n",
    "    # Generate contextual embeddings\n",
    "    contextual_embeddings = generate_contextual_embeddings(sentences)\n",
    "    contextual_embeddings = torch.tensor(contextual_embeddings, dtype=torch.bfloat16).to(tokenizer.device)\n",
    "\n",
    "    # Tokenization\n",
    "    tokenized_input = tokenizer(sentences, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "    tokenized_output = tokenizer(examples[\"target\"], truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    batch_size = tokenized_input[\"input_ids\"].shape[0]\n",
    "    seq_len = tokenized_input[\"input_ids\"].shape[1]\n",
    "    hidden_size = contextual_embeddings.shape[-1]\n",
    "\n",
    "    # Expand contextual embeddings for each token\n",
    "    contextual_embeddings = contextual_embeddings.unsqueeze(1).expand(batch_size, seq_len, hidden_size).to(tokenized_input[\"input_ids\"].device)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": tokenized_input[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized_input[\"attention_mask\"],\n",
    "        \"labels\": tokenized_output[\"input_ids\"],\n",
    "        \"contextual_embeds\": contextual_embeddings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_contextual_embedding_dataset(model_name, spt_name):\n",
    "    \"\"\"\n",
    "    Tokenizes datasets with contextual embeddings for fine-tuning XLM-R & mBERT.\n",
    "    Saves processed train and test datasets with embeddings.\n",
    "    \"\"\"\n",
    "    print(f\"Preparing dataset for {model_name} with {spt_name} embeddings...\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = get_fine_tuned_tokenizer(model_name, spt_name)\n",
    "\n",
    "    # Process Training Dataset\n",
    "    print(\"‚öôÔ∏è Tokenizing train dataset with contextual embeddings...\")\n",
    "    train_tokenized = train_dataset.map(\n",
    "        lambda x: tokenize_with_contextual_embeddings(x, tokenizer),\n",
    "        batched=True,\n",
    "        num_proc=8,  # Parallel processing for speed\n",
    "        load_from_cache_file=False,\n",
    "        desc=f\"Tokenizing train dataset for {model_name} with {spt_name} (Contextual Embeddings)\",\n",
    "    )\n",
    "\n",
    "    # Save train dataset\n",
    "    train_filename = f\"contextual_embedded_{model_name.lower()}_{spt_name}_train\"\n",
    "    save_model_variants_hf(train_tokenized, train_filename)\n",
    "    print(f\"‚úÖ Saved processed train dataset as {train_filename}\")\n",
    "\n",
    "    # Process Test Dataset\n",
    "    print(\"‚öôÔ∏è Tokenizing test dataset with contextual embeddings...\")\n",
    "    test_tokenized = test_dataset.map(\n",
    "        lambda x: tokenize_with_contextual_embeddings(x, tokenizer),\n",
    "        batched=True,\n",
    "        num_proc=8,  # Parallel processing\n",
    "        load_from_cache_file=False,\n",
    "        desc=f\"Tokenizing test dataset for {model_name} with {spt_name} (Contextual Embeddings)\",\n",
    "    )\n",
    "\n",
    "    # Save test dataset\n",
    "    test_filename = f\"contextual_embedded_{model_name.lower()}_{spt_name}_test\"\n",
    "    save_model_variants_hf(test_tokenized, test_filename)\n",
    "    print(f\"‚úÖ Saved processed test dataset as {test_filename}\")\n",
    "\n",
    "    print(f\"üéâ Finished processing dataset for {model_name} with {spt_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding with bpe\n",
    "prepare_contextual_embedding_dataset(\"mBERT\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding with unigram\n",
    "prepare_contextual_embedding_dataset(\"mBERT\", \"unigram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding with bpe\n",
    "prepare_contextual_embedding_dataset(\"XLM-R\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding with unigram\n",
    "prepare_contextual_embedding_dataset(\"XLM-R\", \"unigram\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis-tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
