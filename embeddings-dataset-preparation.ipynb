{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.dataframe import (\n",
    "    save_model_variants_chunk_hf,\n",
    "    load_model_variants_hf, save_model_variants_hf\n",
    ")\n",
    "from IPython.display import display\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from laserembeddings import Laser\n",
    "from utils.gpu import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# gpu device \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Enhance Burmese Contextual Representations\n",
    "- Use LASER, mUSE, and FastText for cross-lingual and morphology-aware training.\n",
    "- Fine-tune mBERT, XLM-R on Burmese dataset after adding contextual embeddings.\n",
    "- Train models again using combined embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk size\n",
    "embedded_train_chunk_sizes = {\n",
    "    \"mbert\": 20,\n",
    "    \"xlm-r\": 20,\n",
    "}\n",
    "embedded_test_chunk_sizes = {\n",
    "    \"mbert\": 5,\n",
    "    \"xlm-r\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splti train data\n",
    "for model_name in [\"mbert\", \"xlm-r\"]:\n",
    "    for spt_name in [\"bpe\", \"unigram\"]:\n",
    "        name = f\"{model_name}_{spt_name}_train\"\n",
    "        train_dataset = load_model_variants_hf(name)\n",
    "\n",
    "        # split and save\n",
    "        save_model_variants_hf(train_dataset, f\"embedded_{name}\", embedded_train_chunk_sizes[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splti test data\n",
    "for model_name in [\"mbert\", \"xlm-r\"]:\n",
    "    for spt_name in [\"bpe\", \"unigram\"]:\n",
    "        name = f\"{model_name}_{spt_name}_test\"\n",
    "        train_dataset = load_model_variants_hf(name)\n",
    "\n",
    "        # split and save\n",
    "        save_model_variants_hf(train_dataset, f\"embedded_{name}\", embedded_test_chunk_sizes[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASER Embeddings\n",
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mUSE (Multilingual Universal Sentence Encoder)\n",
    "muse = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText for Morphology-Aware Training\n",
    "fasttext.util.download_model('my', if_exists='ignore')  # Download Burmese FastText model\n",
    "fasttext_model = fasttext.load_model('cc.my.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize projection layer (1836 → 768) in bf16\n",
    "projection_layer = nn.Linear(1836, 768).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(batch):\n",
    "    \"\"\"\n",
    "    Generates contextual embeddings using mUSE (TensorFlow), LASER, and FastText.\n",
    "    Uses Hugging Face Datasets to process batches efficiently.\n",
    "    Logs errors and stops execution on failure.\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = batch[\"target\"]\n",
    "    sentences = [str(text) if text is not None else \"\" for text in sentences]\n",
    "\n",
    "    # Ensure all sentences are valid strings\n",
    "    sentences = [s.replace(\"\\n\", \" \").strip() if s else \"\" for s in sentences]\n",
    "\n",
    "    # Generate mUSE embeddings (GPU-accelerated)\n",
    "    batch_tensor = tf.convert_to_tensor(sentences)\n",
    "    embeddings_muse = muse(batch_tensor).numpy()  # Shape: (batch_size, 512)\n",
    "\n",
    "    # Generate FastText embeddings\n",
    "    embeddings_fasttext = np.array([\n",
    "        fasttext_model.get_sentence_vector(sentence) for sentence in sentences\n",
    "    ])\n",
    "\n",
    "    # Generate LASER embeddings\n",
    "    embeddings_laser = laser.embed_sentences(sentences, lang=\"my\")\n",
    "\n",
    "    # Stack embeddings\n",
    "    combined_embeddings = np.hstack([\n",
    "        embeddings_muse,\n",
    "        embeddings_laser,\n",
    "        embeddings_fasttext\n",
    "    ])\n",
    "\n",
    "    # Convert to tensor & bf16\n",
    "    tensor_embeddings = torch.tensor(combined_embeddings, dtype=torch.bfloat16)\n",
    "\n",
    "    # Apply projection (1836 → 768)\n",
    "    projected_embeddings = projection_layer(tensor_embeddings).detach().tolist()\n",
    "\n",
    "    return {\"contextual_embeddings\": projected_embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and spt\n",
    "model_name = \"xlm-r\"\n",
    "spt_name = \"bpe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk num\n",
    "chunk_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train path\n",
    "chunk_dataset_path = f\"embedded_{model_name}_{spt_name}_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chunk dataset\n",
    "chunk_dataset = load_model_variants_hf(chunk_dataset_path, chunk_num=chunk_num)\n",
    "print(f\"Chunk Dataset Length: {len(chunk_dataset)}\")\n",
    "display(chunk_dataset.to_pandas().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings\n",
    "chunk_dataset = chunk_dataset.map(generate_embeddings, batched=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display(chunk_dataset.to_pandas().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save chunk dataset\n",
    "save_model_variants_chunk_hf(chunk_dataset, chunk_dataset_path, chunk_num=chunk_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_generated_list = []\n",
    "for i in range(5):\n",
    "    dataset = load_model_variants_hf(chunk_dataset_path, chunk_num=i)\n",
    "\n",
    "    if \"contextual_embeddings\" not in dataset.to_pandas().columns:\n",
    "        not_generated_list.append(i)\n",
    "\n",
    "print(not_generated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-thesis-tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
